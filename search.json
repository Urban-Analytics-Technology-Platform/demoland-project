[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DemoLand",
    "section": "",
    "text": "This project develops a modelling system which is able to quantify several competing aspects of land use in a given urban environment as it currently exists (baseline) and build scenarios under changes that affect the distribution of such land use. It comprises a sequence of models designed to predict the impact of land use changes following large-scale planning decisions on the subset of indicators reflecting the quality of life. At the same time, it aims to determine the optimal land use composition given set indicator levels using neural networks.\nThe project is a partnership between the Geospatial Commission and The Alan Turing Institute, working with Newcastle City Council to develop a modelling system that leverages data science and AI to support decision-making in land use policy. In particular, the project provides tools to help strategic planning by helping decision-makers explore large-scale changes in land use through: - Evaluation of the impact on their policy priorities (house prices, air quality, accessibility to jobs and green space) - Use of machine learning and AI to suggest interventions to achieve policy outcomes."
  },
  {
    "objectID": "intro.html#summary",
    "href": "intro.html#summary",
    "title": "2  Intro",
    "section": "2.1 Summary",
    "text": "2.1 Summary\n\n\n\n\n\n\n\nObjectives\nDevelop modelling system to quantify features of land use in urban environment\n\n\nOutput\nPrediction of the quality of life indicators following a modelled scenarios of development\nstudy case: Tyne and Wear County (Local Authorities: Gateshead, Newcastle Upon Tyne, North Tyneside, South Tyneside, Sunderland)\n\n\nHow\nCreating key indicators for assessing a baseline scenario and future scenarios\n\n\nDuration\n6 months"
  },
  {
    "objectID": "intro.html#project-aims",
    "href": "intro.html#project-aims",
    "title": "2  Intro",
    "section": "2.2 Project aims",
    "text": "2.2 Project aims\nThe project aims to provide insight into the impact of policies affecting land use in cities across the UK, piloting on the case of Tyne and Wear. It:\n\nDerives indicators of quality of life.\nDevelops machine learning models able to predict the impact of land use changes on such indicators.\nAnd inversely, develops a neural network able to predict the required land use change to reach target levels of QoL indicators.\n\nAll these technological components are presented in an interactive tool allowing quick and easy exploration of impacts aimed at policymakers."
  },
  {
    "objectID": "intro.html#explaining-the-science",
    "href": "intro.html#explaining-the-science",
    "title": "2  Intro",
    "section": "2.3 Explaining the science",
    "text": "2.3 Explaining the science\nThe project defines four indicators related to the quality of life, capturing selected dimensions of the environment, society and economy: air pollution, house price, jobs accessibility, and green space accessibility.\nWhile air pollution and house price are composed of the observed values, accessibility metrics were generated for this project.\nFor air pollution and house prices, the project develops machine learning-based, predictive models based on land use variables derived from the Urban Grammar project to allow assessment of land use change.\nThe accessibility metric to two different opportunities (jobs and green space) is calculated for four modes of transport (walking, bicycle, vehicles, public transit) between a relevant set of origins and destinations at the UK census Output Area level.\nThe project is done in collaboration with the Geospatial Commission and Newcastle City Council (NCC). It defines development scenarios of the Tyne and Wear county, for which it reports predicted changes of selected indicators, allowing assessment of a proposed land use change based on machine learning.\nThe outputs are presented in an interactive visual web-based environment allowing quick comparison and presentation for policymakers and professionals."
  },
  {
    "objectID": "intro.html#quality-of-life-indicators",
    "href": "intro.html#quality-of-life-indicators",
    "title": "2  Intro",
    "section": "2.4 Quality of life indicators",
    "text": "2.4 Quality of life indicators\nThe project defies four measurable indicators that can be linked to quality of life.\n\nAir quality\nGreen space accessibility\nHouse prices\nJobs accessibility\n\nThe indicators are first modelled for a baseline scenario reflecting the current land use in the study area. Indicators are modelled using a predictive regression models based on the land use features will that used as explanatory variables and measured using the multimodal accessibility model. See the Methodology for details."
  },
  {
    "objectID": "intro.html#scenarios-of-development",
    "href": "intro.html#scenarios-of-development",
    "title": "2  Intro",
    "section": "2.5 Scenarios of development",
    "text": "2.5 Scenarios of development\nOnce the baseline is created, the project defines a number scenarios of future development (e.g. densification of city centre or land release in the green belt area) and asses the effect of those scenarios on the quality of life indicators.\nSee the chapter on scenarios for details and the interactive mapping tool to explore the results."
  },
  {
    "objectID": "data_sources.html#list-of-data-source",
    "href": "data_sources.html#list-of-data-source",
    "title": "3  Data Sources",
    "section": "3.1 List of data source",
    "text": "3.1 List of data source\nBelow is a list of data sources organised by the purpose\n\n3.1.1 Project-wide\n\nOS | 2011 Census Output Areas | link\n\n\n\n3.1.2 Accessibility indicators\n\nONS | Population Weighted Centroids (PWC) of Output Areas | link\nONS | Workplace zones | link\nOS | Open Greenspace | link\nOSM | OpenStreetMap network data | link\nITS Leeds | UK GTFS data | link\n\n\n\n3.1.3 Air quality\n\nDEFRA | UK AIR | link\n\n\n\n3.1.4 House price\n\nChi et al. | A new attribute-linked residential property price dataset for England and Wales 2011-2019 | link\n\n\n\n3.1.5 Explanatory variables for modelling\n\nONS | Population estimates | link\nONS | Workplace population | link\nCopernicus | CORINE Land Cover classification | link\nThe Alan Turing Institute | Spatial Signatures of Great Britain | link"
  },
  {
    "objectID": "method.html#building-indicators",
    "href": "method.html#building-indicators",
    "title": "4  Methodology",
    "section": "4.1 Building Indicators",
    "text": "4.1 Building Indicators\nThe original list of indicators (see Intro) was pruned after an initial review of the available data, software, interests of the stakeholders.We resolved to 4 indicators of interest:\n\nAir quality\nGreen space accessibility\nHouse prices\nJobs accessibility\n\nFor each of these indicators, we have detailed below how they are generated. This step represents the basic scenario.\nWe have two different types of indicators: while air quality and house prices are “actual data” measurements, accessibility is estimated and generated in a deterministic way, so it can’t be directly modelled/predicted using some explanatory variables.\n\n4.1.1 Accessibility calculation\nFor accessibility computation, we consider the potential accessibility (cumulative) to green spaces and jobs, that represent the opportunities. We consider a set of (punctual) origins and opportunities’ destinations and the time it takes to move between them on the road network, given different transport modes. In order to calculate the time it takes from each origin to reach each destination, we need to have a Time Travel Matrix (TTM) between origins and destinations for different means of transport.To build this, we can generate a graph/network starting from two data sources: data for the road network and data for public transportation schedules. Once a TTM is built between one set of origins and one set of destinations for a given mode of transport, we can run accessibility analysis on it.\n\nOrigins - For the scope of the project, we consider as origins the coordinates of the Population Weighted Centroids (PWC) of Output Areas (OA).\nDestinations - Per each destination we need to provide the coordinates and a datum for the opportunity (or ‘supply’, in our case this is the land use), for example the number of jobs available (other opportutnities could be number of schools, health centres, other types of countable features).\nFor jobs count we consider as destinations the PWC of the working population per Workplace Zones (WPZ) from the 2011 Census (data available and definition). As an opportunity measure (the job counts) we make the approximation that the number of workers equals the number of jobs available. This is an approximation we take in order to preserve the spatial location of the jobs, that is relevant in the calculation of the time travel matrix. In fact the number of jobs in the Census is at OAs level, but the PWC for this aggregated level can be off-centered in relation to where people work.\nFor green spaces accessibility we use the open data set available from Ordnance Survey (OS). In particular as a first approximation we consider the layer “Access points” from this datum. This gives the coordinates of the access points to green spaces in all Great Britain, which we take as destinations.As an opportunity measure we count the areas of the greenspace (layer “Sites”) to which these points give access to, see below for details on how we consider the cumulative opportunity of this datum.\n\n1. Indicator definition\n\nJobs accessibility\n\n\nNumber of jobs accessible by public transport and walking in 15 minutes\n\n\nGreen spaces accessibility\n\n\nSum of the areas of green space sites reachable within 15 minutes\n\n\nobtain greenspace sites from OS\n\nfilter out not relevant categories (allottments, golf courses, bowling greens)\nretain entrances on the edge of the sites\nassociate\n\n~~ obtain “missing” areas from Corine or OSM~~ idea for future improvement\nget sites’ area\nfilter entrances within time threshold (15min) per each origin (OA)\nconsider unique values for parks (can be reached in )\ngenerate metric per each OA as Sum [reachable site size]\n\n2. Build time travel matrix (TTM)\nWe can build a TTM from two data sources: the roads network and a time table for public transport. We can obtain the first by donwloading OpenStreetMap (OSM) data for the area of interest. Time table for public transport in GTFS format is available in England from UK2GTFS. We use GTFS data because more of compatibility with the ttm calculation package.\n\nget time table for public transport &gt; GTFS data\nget roads network &gt; OSM data\ngenerate network graph &gt; r5 engine ([Conveyal(https://github.com/conveyal/r5)]) &gt; r5py package\ngenerate ttm for 4 different modes &gt; ‘transit’, ‘bike’, ‘car’, ‘walking’\ntime is fixed atm &gt; idea for future improvement: edit for taking into account different day of the year/week, time of the day\n\n3. Run accessibility analysis\n\nget land use data (opportunities detailed above in _*Destinations_)\njobs &gt; run tracc package on the ttm per each transport mode:\n\ncompute impedance function based on a 15 minute cost (cumulative)\nsetting up the accessibility object IE joining the destination data to the travel time data\nmeasuring potential accessibility to jobs as cumulative sum of opportunities at destination per each origin\n\ngreenspace &gt; convert the tracc functions to work only on reachable sites’ area, on the ttm per each transport mode:\n\ncompute impedance function based on a 15 minute cost (cumulative)\njoin the destination data to the travel time data\nper each OA (origin), filtering only entrances with time travel within the threshold\nper each OA, filter entrances (only one per park)\nper each OA, assign metric as sum[parks’ area]\n\n\n\n\n4.1.2 Air quality index\nWe develop an air quality index as a composite of \\(PM_{2.5}\\), \\(PM_{10}\\), \\(NO_{2}\\) and \\(SO_{2}\\) particle values derived from the UK AIR project run by DEFRA with data available as a 1km grid (https://uk-air.defra.gov.uk/data/pcm-data). The composite index follows the methodology of European Environmental Agency, reflecting the relative health risk associated to the exposure to particle intensities.\n\nThe bands are based on the relative risks associated to short-term exposure to PM2.5, O3 and NO2, as defined by the World Health Organization in its report on the Health Risks of Air Pollution in Europe project (HRAPIE project report).\nThe relative risk of exposure to PM2.5 is taken as basis for driving the index, specifically the increase in the risk of mortality per 10 µg/m3 increase in the daily mean concentration of PM2.5.\nAssuming linearity across the relative risks functions for O3 and NO2, we calculate the concentrations of these pollutants that pose an equivalent relative risk to a 10 µg/m3 increase in the daily mean of PM2.5.\nFor PM10 concentrations, a constant ratio between PM10 and PM2.5 of 1:2 is assumed, in line with the World Health Organization´s air quality guidelines for Europe.\nFor SO2, the bands reflect the limit values set under the EU Air Quality Directive.\n\nThe relationship between \\(PM_{2.5}\\) : \\(PM_{10}\\) : \\(NO_{2}\\) : \\(O_{3}\\) : \\(SO_{2}\\) is then equal to 1 : 2 : 4 : 5 : 10. The combined index can then be computed as \\[Q_{air} = \\frac{PM_{2.5}}{1} + \\frac{PM_{10}}{2} + \\frac{NO_{2}}{4} + \\frac{O_{3}}{5} + \\frac{SO_{2}}{10}\\]\nExcept for the \\(O_{3}\\), UK AIR reports all as a concentration in \\(\\mu g \\cdot m^{-3}\\). \\(O_{3}\\) is reported as a number of days above a threshold of 120 \\(\\mu g \\cdot m^{-3}\\) and cannot be used in this formula but even EEA omits data when unavailable so we shall be able to create the index based on 4 remaning measurements.\nIt shall also be considered that UK AIR is not representing a direct measurements but a model.\nThe data from the 1km grid are spatially interpolated to Output Area geometry. The index itself is computed on the grid.\n\n\n4.1.3 House price\nAn optimal way of working with house prices in the modelling exercise like ours is to use price per sqm. However, those are not generally available at the level of Output Area or similar. Luckily, we can retrieve such data from the “A new attribute-linked residential property price dataset for England and Wales 2011-2019” project by Chi et al. available from 10.5255/UKDA-SN-854240. That contains individual house prices, total floor area and a resulting price per sqm resulting from a combination of Land Registry Price Paid Data and Domestic Energy Performance Certificates.\nWe use the data from years 2018-2019 and compute the mean price per sqm per output area. Given the data is not fully up-to-date, the modelling results will be presented as a percentual increase or decrease compared to the baseline value rather than in absolute values."
  },
  {
    "objectID": "method.html#explanatory-variables",
    "href": "method.html#explanatory-variables",
    "title": "4  Methodology",
    "section": "4.2 Explanatory variables",
    "text": "4.2 Explanatory variables\nWe use a set of explanatory variables describing the environment that can be changed to model different scenarios and have, at the same time, explanatory power to predict our four indicators.\n\n4.2.1 ONS population estimates\nWe use the ONS population estimates on the OA level for mid-2020. The other data used in the project are generally reflecting the period 2018-2020, so we want to ensure we describe the compatible point in time. The dataset is retrieved from the ONS. Given it is reported on Output Area level, it can be simply joined.\n\n\n4.2.2 Workplace population by industry\nWorkplace population is coming from the Census 2011 and is reported on Workplace Zone geometries. We use the data preprocessed in the Urban Grammar project that aggregated industries into following groups:\n\nA, B, D, E. Agriculture, energy and water\nC. Manufacturing\nF. Construction\nG, I. Distribution, hotels and restaurants\nH, J. Transport and communication\nK, L, M, N. Financial, real estate, professional and administrative activities\nO,P,Q. Public administration, education and health\nR, S, T, U. Other\n\nThe data is then interpolated from Workplace Zones to Output Areas.\n\n\n4.2.3 CORINE Land Cover classification\nWe use CORINE Land Cover Classification for 2018 distributed as polygons of contiguous areas belonging to the same classs. We use the data extracted for the Great Britain within the Urban Grammar project and interpolate the data onto Output Areas capturing a proportion of each OA covered by each class. We further filter out fully or nearly invariant classes and use only:\n\nDiscontinuous urban fabric\nContinuous urban fabric\nNon-irrigated arable land\nIndustrial or commercial units\nGreen urban areas\nPastures\nSport and leisure facilities\n\n\n\n4.2.4 Urban morphometrics\nUrban morphometrics offers a way of describing physical built environment (buildings, streets) in a set of measurements capturing different aspects of morphological elements. We directly use the set measured within the Urban Grammar project, presented as individual characters (prior contextualisation) and interpolate their values from the original geometry (enclosed tessellation cells) to output areas. That way, we already get a contextual version using the project-specific aggregation to OA. This gives us 59 morphometric variables.\n\n\n4.2.5 Variable pruning\nGiven some of the explanatory variable were collected for a different purpose than modelling and with a different geographical extent in mind, it may happen that within our limited area of interest (Tyne and Wear), some of the variable are collinear. Those may negatively affect the performance of the predictive models and it is better to limit their number to minimum. We, therefore, measure Pearson’s correlation index and Spearman Rank correlation index between all pairs of explanatory variables and from each pair with the absolute value of the index above 0.8 retain only one, ideally the one that is more interpretable.\nThe final set contains 59 explanatory variables and the only morphometric were pruned down.\n\npopulation estimate\nA, B, D, E. Agriculture, energy and water\nC. Manufacturing\nF. Construction\nG, I. Distribution, hotels and restaurants\nH, J. Transport and communication\nK, L, M, N. Financial, real estate, professional and administrative activities\nO,P,Q. Public administration, education and health\nR, S, T, U. Other\nLand cover [Discontinuous urban fabric]\nLand cover [Continuous urban fabric]\nLand cover [Non-irrigated arable land]\nLand cover [Industrial or commercial units]\nLand cover [Green urban areas]\nLand cover [Pastures]\nLand cover [Sport and leisure facilities]\narea of building\ncourtyard area of building\ncircular compactness of building\ncorners of building\nsquareness of building\nequivalent rectangular index of building\ncentroid - corner mean distance of building\ncentroid - corner distance deviation of building\norientation of building\narea of ETC\ncircular compactness of ETC\nequivalent rectangular index of ETC\ncovered area ratio of ETC\ncell alignment of building\nalignment of neighbouring buildings\nmean distance between neighbouring buildings\nperimeter-weighted neighbours of ETC\nmean inter-building distance\nwidth of street profile\nwidth deviation of street profile\nopenness of street profile\nlength of street segment\nlinearity of street segment\nmean segment length within 3 steps\nnode degree of junction\nlocal proportion of 3-way intersections of street network\nlocal proportion of 4-way intersections of street network\nlocal proportion of cul-de-sacs of street network\nlocal closeness of street network\nlocal cul-de-sac length of street network\nsquare clustering of street network\nlocal degree weighted node density of street network\nstreet alignment of building\narea covered by edge-attached ETCs\nbuildings per meter of street segment\nreached ETCs by neighbouring segments\nreached ETCs by tessellation contiguity\narea of enclosure\ncircular compactness of enclosure\nequivalent rectangular index of enclosure\norientation of enclosure\nperimeter-weighted neighbours of enclosure\narea-weighted ETCs of enclosure"
  },
  {
    "objectID": "method.html#modelling-regression-analysis",
    "href": "method.html#modelling-regression-analysis",
    "title": "4  Methodology",
    "section": "4.3 Modelling / regression analysis",
    "text": "4.3 Modelling / regression analysis\nWhile the accessibility indicators are a result of a deterministic model based on a fixed travel-time matrix, hence any scenario modelling can re-use it and change only the raw values at the destinations, we need to develop predictive models to be able to see the change of air quality and house price.\nBoth models are based on the same architecture, a Histogram-based Gradient Boosting Regression Tree as implemented in the scikit-learn Python package, and a set of 59 explanatory variables listed above. To ensure we are able to properly captrue the spatial nature of the indicators, we add another 59 variables on top that are a result of a spatial lag of the original set. The spatial lag is measured as a mean value of the variable within a set neighbourhood, which definition is determined empirically. We test the neighbourhoods based on contiguity (from order of contiguity 1 to 5 inclusive of lower-order neighbors), Euclidean distance (500m, 1000m, 2000m) and their unions. Each option is then part of the grid search aimed at the selection of the best model parameters and the best defition of the spatial lag in relation to the model performance metrics (R2, MSE, ME). Model parameters that are being assessed are learning rate, maximum number of iterations and maximum number of bins. For more details, see the implementation in the Air Quality notebook and the House Price notebook.\nFurthermore, we have experimented with the geographical extent of the training data. While the original models were based only on the data from the study area (Tyne and Wear), we have tested models trained on other geographical subsets:\n\nwhole England\nEngland excluding Greater London, known to be an outlier within the country that may not help in predictive quality within Tyne and Wear\nTyne and Wear plus all OAs belonging to “Urbanity” classes from the rest of England\n\nThis was to add additional robustness to the model by training on a wider set of data.\n\n4.3.1 Resulting model specifications\nThe resulting models, selected based on their performance, are based on the following specifications:\nAir Quality\n\nSpatial extent: Tyne and Wear plus all OAs belonging to “Urbanity” classes from the rest of England\nSpatial lag: A union of 5 orders of Queen contiguity and 2000m distance band\nModel parameters: learning_rate=0.2, max_bins=64, max_iter=1000\n\nThe model performance (R2) is ~0.8.\nHouse Price\n\nSpatial extent: England excluding Greater London\nSpatial lag: 5 orders of Queen contiguity\nModel parameters: learning_rate=0.1, max_bins=128, max_iter=1000\n\nThe model performance (R2) is ~0.5."
  },
  {
    "objectID": "method.html#building-scenarios",
    "href": "method.html#building-scenarios",
    "title": "4  Methodology",
    "section": "4.4 Building scenarios",
    "text": "4.4 Building scenarios\nThe mechanism for scenario building is based on four macro variables, which combination driving the sampling mechanism deriving the 59 variables used in the modelling. The four variables are Level of urbanity, which is a proxy for a signature type of spatial signatures as defined in the Urban Grammar project, Use of buildings controlling the ratio between residential and commercial or industrial use, Job types, controlling whether job structure in each output area is more white-collar or blue-collar, and Green space, reflecting the amount of formal green space (i.e. parks).\nScenarios are modelled by specifying the macro variables on output areas where the change is assumed. Any of the four variables can be specified in combination with any other. The algorithm then samples the data from either baseline capturing the existing state or from the known distribution of values per signature type based on the country-wide data.\nThe first step in the sampling procedure is the selection of a signature type. If it is not changed, subsequent steps modify the baseline. Otherwise, we sample the values for a set signature type reflecting its common characterisation as observed across Great Britain. For example, if we specify the Local urbanity signature type for an output area that had Dense urban neighbourhoods assigned, we look at how Local urbanity usually looks like and sample all the required values from a narrow normal distribution around the median of the nation-wide distribution. Further macro variables are adjusting these values. Use will change the variables of population and workplace population, job types will change the distribution of jobs to job type categories, and green space will allocate new parks onto an output area (adjusting other values like population accordingly).\nDevelopment of each scenario is then composed of a few simple steps:\n\nSelect output areas that are supposed to change\nAssing target level of urbanity for each\nAssing another macro variable for each\nSample the values as input for the model\nRun the models to assess the effect of tested changes"
  },
  {
    "objectID": "scenarios.html#scenario-1-low-density-residential-development",
    "href": "scenarios.html#scenario-1-low-density-residential-development",
    "title": "5  Scenarios",
    "section": "5.1 Scenario 1: Low-density residential development",
    "text": "5.1 Scenario 1: Low-density residential development\nThis scenario models the situation where land in the green belt is released for development. The area is taken over by a large developer used to build residential areas around the country. The new neighbourhood is a combination of low-rise detached and semi-detached housing with only minimal additional land use. The primarily residential neighbourhood does not generate a significant amount of jobs, inducing higher traffic to industrial zones and Newcastle city centre. The development is located west of the city around Callerton.\nThe new development is modelled as a combination of open sprawl and disconnected suburbia signature types, combined with an estimation of the allocation of new population and a small number of jobs in retail and education.\nThe model results in approximately:\n\n63 000 new residents\n9 250 new jobs (14% of residents)\nno new parks"
  },
  {
    "objectID": "scenarios.html#scenario-2-mid-density-mixed-neighbourhood",
    "href": "scenarios.html#scenario-2-mid-density-mixed-neighbourhood",
    "title": "5  Scenarios",
    "section": "5.2 Scenario 2: Mid-density mixed neighbourhood",
    "text": "5.2 Scenario 2: Mid-density mixed neighbourhood\nThis scenario models the development in the green belt under the idea of a 15-minute neighbourhood that is dense, therefore taking up less space and mixed in terms of use. Such a neighbourhood contains not only residential housing but also a few places for new retail, commercial, and other uses. As such, it should be more self-sufficient than the low-density Scenario 1, inducing less traffic from the neighbourhood to other areas in the city. The development is assumed to be in the same area west of Callerton as in Scenario 1. The form is composed more of row houses and multi-story tenement buildings forming the centre of the new neighbourhood.\nIt is modelled as a combination of accessible suburbia, connected residential neighbourhoods and dense residential neighbourhoods signature types, with an approximation of new population and job allocation. Land cover is changed accordingly to discontinuous urban fabric and continuous urban fabric, but on a smaller area than in Scenario 1, leaving space dedicated to large urban parks.\nThe model results in approximately:\n\n54 000 new residents\n10 500 new jobs (19 % of residents)\n2 300k sq.m. of new parks"
  },
  {
    "objectID": "scenarios.html#scenario-3-densification-of-inner-city",
    "href": "scenarios.html#scenario-3-densification-of-inner-city",
    "title": "5  Scenarios",
    "section": "5.3 Scenario 3: Densification of inner city",
    "text": "5.3 Scenario 3: Densification of inner city\nThis densification scenario models a high-density development in the already developed areas, following the gradual infill and rebuilding existing buildings into higher ones with more mixed-use. It is a long-term strategy aimed at preserving green spaces (especially the green belt) and creating 15-minute neighbourhoods in the existing city by adding new layers of functionality and new inhabitants to places that are already built. The scenario affects most of the city, with higher densification levels around local centres and main streets and lower levels in suburban residential areas.\nIt is modelled as a change of signature types based on their hierarchy to higher order ones and related estimations of new population and job allocation. Land cover changes from discontinuous urban fabric to continuous urban fabric.\nThe model results in approximately:\n\n25 000 new residents\n24 000 new jobs (96% of residents)\nno new parks"
  },
  {
    "objectID": "scenarios.html#scenario-4-brownfields-to-dense-neighbourhoods",
    "href": "scenarios.html#scenario-4-brownfields-to-dense-neighbourhoods",
    "title": "5  Scenarios",
    "section": "5.4 Scenario 4: Brownfields to dense neighbourhoods",
    "text": "5.4 Scenario 4: Brownfields to dense neighbourhoods\nExisting brownfield land is redeveloped into high-density neighbourhoods with mixed-use, providing housing, services, and commercial units in an attempt to densify the inner city without affecting existing areas. Compared to scenario 3, this strategy is less invasive but has a lower scale. However, both scenarios can be potentially combined, as shown in Scenario 6.\nIt is modelled as a change of signature types on brownfield land to dense urban neighbourhoods and local urbanity, plus relevant changes in land cover, population and job allocation.\nThe model results in approximately:\n\n55 700 new residents\n-1 000 new jobs (0% of residents)\nno new parks"
  },
  {
    "objectID": "scenarios.html#scenario-5-brownfields-into-parks",
    "href": "scenarios.html#scenario-5-brownfields-into-parks",
    "title": "5  Scenarios",
    "section": "5.5 Scenario 5: Brownfields into parks",
    "text": "5.5 Scenario 5: Brownfields into parks\nContrary to Scenario 4, this scenario assumes that all the brownfield land is turned into urban parks with no development. While it does not help to solve the issue of the capacity of a city, it may be viewed favourably by the local population and can balance potential densification as outlined in Scenario 3. Both Scenarios 3 and 5 can be combined, as shown in Scenario 7.\nIt will be modelled as a change of signature types on brownfield land to park/warehouse land plus relevant land cover changes and removal of any population and job allocation.\nThe model results in approximately:\n\n0 new residents\n-20 000 new jobs\n6 230k sq.m. of new parks"
  },
  {
    "objectID": "scenarios.html#scenario-6-urbanisation-to-the-edge",
    "href": "scenarios.html#scenario-6-urbanisation-to-the-edge",
    "title": "5  Scenarios",
    "section": "5.6 Scenario 6: Urbanisation to the edge",
    "text": "5.6 Scenario 6: Urbanisation to the edge\nThis scenario models the city following the densification strategies outlined in both Scenarios 3, where we target higher density to already-dense central areas, and Scenario 4, we model the development of dense neighbourhoods in the brownfield and industrial areas around the River Tyne. As such, the scenario combines changes from Scenarios 3 and 4.\nThe model results in approximately:\n\n66 000 new residents\n30 000 new jobs (45% of residents)\nno new parks"
  },
  {
    "objectID": "scenarios.html#scenario-7-urbanisation-with-greenery",
    "href": "scenarios.html#scenario-7-urbanisation-with-greenery",
    "title": "5  Scenarios",
    "section": "5.7 Scenario 7: Urbanisation with greenery",
    "text": "5.7 Scenario 7: Urbanisation with greenery\nThis scenario directs changes to two locations in two different directions. First, it assumes the densification of an already-dense city centre as outlined in Scenario 3, adding further population, jobs, and services to the area. Second, it combines this densification with the creation of new large parks around the River Tyne, where current brownfields and industrial areas are. As such, the scenario is, in principle, a combination of changes from Scenarios 3 and 5.\nThe model results in approximately:\n\n1000 new residents\n30 000 new jobs\n6 230k sq.m. of new parks"
  },
  {
    "objectID": "scenarios.html#results",
    "href": "scenarios.html#results",
    "title": "5  Scenarios",
    "section": "5.8 Results",
    "text": "5.8 Results\nYou can see the results of these scenarios in the interactive web application."
  },
  {
    "objectID": "notes.html#february",
    "href": "notes.html#february",
    "title": "6  Notes",
    "section": "6.1 February",
    "text": "6.1 February\n\n6.1.1 Greens space sites\nA first accessibility computation using Ordnance Service (OS) open data was rejected, as not in line with expected results.\nThe reason for this are:\n\nthe data misses some vast green sites outside of town\nthe chosen metric was not proper [IE count the n of access points accessible within 15 min from origins]\n\nDealing with the two issues separately:\n\nThe good thing of the OS data is that they are accurate (resolution, categories) AND they contain also the access points (which for everyone’s sake we are gonna refer to as entrances). NOTE: we need entrances to green space as the destinations for our time travel matrices. A good candidate to make up for not covered areas is the landuse layer from OpenStreetMap (OSM).\n[from OSM landuse layer we consider the tags/fields: cemetery, forest, nature reserve, park, recreation ground]\nOSM data has very much good cover of the existing green sites, but: lacks a proper classification, doesn’t have entrances to sites, doesn’t distinguish between public/private/military spaces, therefore the use of OSM would bring to over-estimate green spaces. Example: in OSM we have some side-road areas inside Metrocentre classified as forest.\nIn order to understand parks where people actually can/does pass through, a cross-check was carried out manually looking for parks with existing trails (passing through them) using https://hiking.waymarkedtrails.org/ AND Google Street View to check entrances to parks/greens/ etc [IE some entrances actually show a sign that make it clear if it’s a public access or not]\nList of parks/green spaces which we would want to consider in the green belt/suburbs of Tyne and Wear (and their status, IE open/public etc):\n\n\n\npark name\nstatus\nlocation\n\n\n\n\nChopwell Woodland\nopen\nSW\n\n\nMilkweelburn Wood\nopen\nSW\n\n\nWatergated Park\nopen\n\n\n\nSilverhill Wood / Ravesworth Estate\nclosed\n\n\n\nBanesley Lane woodland\nopen\n\n\n\nHedley Hall Woods\nopen\n\n\n\nSpen Banks / Sherburn Green Woods\nopen\n\n\n\nClinty Wood\n?\n\n\n\nGibside national Trust\nclosed ($$)\n\n\n\n\n\nWe want to generate a metric that take into account the proximity to a green space AND the size of the site you are accessing to. It doesn’t matter how many access points are accessible, as long as one gives you access to the site within 15 min (walk, bike, other means)\nMetric: once generated the time travel matrix (OAs centroids to GS entrances) retain one access point per park, IE consider only once each park that is reachable at least through one access point in 15 min. Then sum up all the areas of the reachable parks.\nIn order to do so, we need to clean the data from the eccessive entrances: many sites are included within other ones (for example a playground or tennis court can be enclosed in a public park). These enclosed sites also generate an overestimate of the accessible area, because they are overlapping with the main major park - which is the only category/feature/polygon we would like to consider.\nFirst of all we clean the OS data from not-wanted categories, IE areas which are green but not openly accessible by the public. These include: allottments, golf courses, bowling greens.\nWe then can do this consideration: most of the times it’s the 2 categories Playing Field and Public Park Or Garden that contain other categories within their boundaries. We could play with this. Other Sport Facilities also contains and is contained, but mostly is contained.\nThe hierarchy of the layers seems to be roughly this: Public Park Or Garden contains Playing Field contains Other Sport Facilities contains rest of categories.\nAfter several trials with spatial joins and other geospatial operations, have managed to obtain a good results by separating the above categories into single layers and performing operations among them. See notebook greenspace_datacleaning.ipynb for details.\n\n\n6.1.2 Open issues/questions on indicators building\nAccessibility\naccessibility computation:\n\nrouting engine: 5r\n\nin python:\n\ntogether with tracc or pysal/access\n~~use conveyal with mongoDB ~~(not tried yet)\n\nin R: wrapped within r5r (not tried yet)\n\nttm generation:\n\nwe only consider origins within the county, what about extra zonal areas?\ncan generate one single table with multimodal trip &gt; can create a comprehensive table using scripting\nhow does it work with scenarios generation - especially for OSM\nusing random date and time in database: 2023,1,19,8,30;\n\ncould generate several network graphs and get median value of them all (see Pereira about this)\noptimal date? (Journey Time Statistics use a Tuesday in October)\n\nthe ttm with origins OAs (centroids) to destinations LSOAs (centroids) for transit (leg_mode walk) takes 39 min!\nOAs as origins … while we could “force” the points to the nearest road node (see Statistics method mentioned above)\n\nGTFS data:\n\ngood source for UK or do we need to generate it ourselves from\ncan we edit the GTFS file, in case we want add a route / stop?\n\nmeasuring acc to jobs:\n\ncan we find more detailed data of where people work?\nand of where people live?\n\n15 min neighborhoods\n\napproximating where people live, IE can we improve the location from actual approximation to population weighted centroids?\n\n\nGTFS data handling\nChecking the possibility to view and edit GTFS data with [gtfs_kit](https://gitlab.com/mrcagney/gtfs_kit) in Python. All the trials are in python/gtfs_kit_trials.ipynb. Note: created env_gtfs-kit.yml environment to test the package.\nworking with the files in raw/GTFS:\n\nitm_all_gtfs.zip:\n\nGTFS file downloaded from https://data.bus-data.dft.gov.uk/timetable/download/gtfs-file/all/\nthis file was accessed though the website https://www.transit.land/feeds/f-busdftgov~uk\nIt contains all the UK buses only? CHECKING\n\nitm_north_east.gtfs.zip:\n\nshould be a subset of the one above for North East England\ndownloaded from same source, where I have managed to get subset (don’t remember how)\n\n\nNE.zip:\n\nGTFS generated and downloaded from UK2GTFS https://github.com/ITSLeeds/UK2GTFS, see releases\nthis file has no shape.txt but it’s for North East England\n\n\nHave done some trials in Qgis to view the routes (starting from the file shape.txt), we want to understand if only buses are in this GTFS data or also for example the light rail line (Yellow, owned and managed by Nexus) is included.\nIt might be a disadvantage to use the whole UK data, but it might be more complete than the local one (NE) generated in UK2GTFS.\nWe would like also to be able to edit the GTFS data, adding a line/stop.\n:bangbang: :loud_sound: update :loud_sound: :bangbang:\ndecided that the best source to use (compromise of coverage, file size, reliability) is the north_east version of bus-data.dft.gov\nin fact it looks loike the metro line (yellow) is included\nTwo screenshots from sources used to cross-check the data: 1. Dustin’s bus spotting website (bus spotting) \n\npersonal map on Felt with added transport network layer \n\n\n\n6.1.3 Jobs location\nWe have number of jobs as a datum down to LSOA level, it comes from nomis\n\nAn employer survey of the number of jobs held by employees broken down by full/part-time and detailed industry (5 digit SIC2007). The survey records a job at the location of an employees workplace. Available from country down to lower level super output area and Scottish datazone.\n\nFor destinations, when calculating the travel time matrix (TTM) to jobs locations, we can use then the population weighted centroids (PWC) of LSOAs areas. This assumption though affects the distances we calculate, in particular when considering vast industrial/business estates, where very few population is present - in this case in fact the PWC centroid will be probably (or could be) located in a marginal point of the polygon (IE LSOA area), resulting in invalid results.\nSee as an example the image below (created in Qgis) showing the Team Valley trading estate in Gateshead location\n Red dots = OA centroids (our origins)pink lines = LSOAs boundaries yellow dots = LSOAs centroids blue dots = WPS centroids\nLooking for alternatives, I have found a geography for the Census that takes into account the working population.\nWorkplace Zones (WPZ)\n\nWorkplace Zones are a small-area geography designed to contain a consistent number of workers allowing workplace statistics to be released at a more granular level.\n\nThe data available at this geographic level are here and they include the Workplace population (table WP101EW)\n\nThis dataset provides 2011 Census estimates of the workplace population in England and Wales by residence type (household or communal resident), by sex and by age. The estimates are as at census day, 27 March 2011.\n\nWe have decided to use the number of workers as a proxy for jobs count (STRONG ASSUMPTION). We can then use as destinations the WPZ centroids, and as n. of jobs (opportunities) the working population for the WPZ. A stronger variable could be generated using the location from the WPZ (destination), and as opportunities a interpolation from the LSOA jobs count to the WPZ areas. Note that the relation between Output Areas and WPZ is that “in England and Wales they [WPS] are designed to align with Middle Layer Super Output Areas (MSOAs)”.\nConclusions: In any case we need to make an approximation: using LSOA we give up on location, using WPZ we give up on actual (estimated?) job count.\nThe ideal situation would be to have the number of jobs and their location / employment centres. A way to deal with the lack of data on this, could be to generate it using Free Company Data Product\n\ndownloadable data snapshot containing basic company data of live companies on the register\n\nFrom this data set we can get number of companies registered at postcode level (see data fields here) which is quite detailed, and then find a way to aggregate/interpolate them to identify “job centres”. We have postcodes centroids from geoportal-gov.\nAs a future improvement, keep in mind the idea to generate more precise job locations, either by using the House company data, or other sources (and ideas)."
  },
  {
    "objectID": "notes.html#january",
    "href": "notes.html#january",
    "title": "6  Notes",
    "section": "6.2 January",
    "text": "6.2 January\nJanuary starts basically as a continuation of the work started in December.\nWarming up Image created in Qgis showing median house prices (year ending March 2022) and green spaces in Tyne and Wear county (current case study):  Note:\n\nhouseprices data are associated to the LSOA boundaries shp via the python code in data_prep.ipynb\ngreen spaces are from the OS open data base see description here\n\n\n6.2.1 Accessibility accessibility accessibility\n\nAccessibility is understood as the ease with which a person can reach places and opportunities from a given location and it results from the interaction between the transport system, land-use patterns, and the constraints of individuals  (Pereira et al. 2019, Distributional effects of transport policies on inequalities in access to opportunities in Rio de Janeiro, Journal of Transport and Land Use 12(1): 741-764)\n\nLet’s start from green spaces (easier?) to create methodology, then pass on to jobs…\n\nresolution (LSOA…?)\nfind relation to land use\ngenerate indicators:\n\nrelevant variables\nrelevant scenarios\n\n\n\nIDEAS in random order\n\naccessibility definition??\nIdentify the shortest path between two locations using the OSM transport network:\n\nroutino application for finding a route between two points using OSM\nvalhalla open source routing engine and accompanying libraries for use with OSM\nOpenTripPlanner open-source multimodal trip planning software system\nPlan4better Geo Open Accessibility GOAT tool\nOSMnx Python package\nbuild from OSM and implementing Dijkstra myself (??? @Dustin suggestion)\nR5 - Conveyal:\n\nin R: r5r\nin Python: r5py\n\n\n… check Propensity to Cycle Tool by Robin? [PTC]\ndefine the paths we want to see https://en.wikipedia.org/wiki/Shortest_path_problem#Algorithms\n\nfrom where to where?\nhow to define people’s home… centroids buildings??\n\n\n\n2 ways of seeing accessibility:\n\nbetween “areas” (IE “from this LSOA I can access N schools/jobs/… located in other LSOAS”) calculated using origin/destination matrix for centroids (pop weighted likely) and cumulative sum of opportunities\nfrom the amenity (school/job/hospital…)  generate a N-min “isochrone” (depending on mode) and see how it overlaps with population distribution (at LSOA level? the more detailed the merrier)\n\napparently the distinction is between passive and active accessibility see\n\nNote  When you have available the 2 datasets:\n\nland_use_data - file with columns like population, jobs, school per LSOA (or whichever geography unit)\ntravel_matrix - origin destination matrix with travel cost column (can use time rather than distance, as a cost proxy) per LSOAs (from_id, to_id, travel_time)\n\nyou can run and play around with accessibility, a package in R from Rafa Pereira from ipeagit\n\ncalculate active and passive accessibility levels using multiple accessibility metrics, such as cumulative opportunities (using either a travel cost cutoff or a travel cost interval), minimum travel cost to closest N number of activities, gravitational measures and different floating catchment area methods.\n\n\nor run tracc or pysal/access pr rpy5 on the TTM\n\neven better: from the above (written in R), reference to Python stuff here:\n\n\ntracc: Transport accessibility measures in Python\naccess: Spatial Access for PySAL\n\naceso: a lightweight Python package for measuring spatial accessibility\n\n\n\n… see application and comments directly in accessib.ipynb\n\nIn order to run these functions we need to create/have the following input files:\n\ntransit time data (origin-destination matrix with time) between origins and destinations\nsupply / opportunity:\n\n\njob counts per area can download data at LSOA level (one file per LAD, or full county) from Nomis BRES\n\n\nother type of opportunity (ex: n of groceries, n of schools, etc… extension of greenspace? n of access points?)\n\n\n\n as a proxy for future complicated stuff and to try something for now, let’s generate the number of access points (to greenspaces) per LSOA… what would be the fastest way:\n\nQGIS analysis (sure a function exists for this, but this solution is valid only temporarily, better the next one)\nin Python with Geopandas (or similar stuff) I assume it’s doable\n\nA good explanation of the process is in the r5py documentation\n\nTrials\nDifferent trials for accessibility calculation are accessible as notebook files within the python folder, generally named as accessib_****_.ipynb\n1. OTP\nCalculations for OTP in the script [accessib_OTP.ipynb](./../python/accessib_OTP.ipynb)\nStarted by the tutorial at https://github.com/marcusyoung/otp-tutorial\n\nYoung, M. (2021). OpenTripPlanner - creating and querying your own multi-modal route planner.\n\nExamples of 15-90 minisochrones from (54.96835, -1.60778) generated using OTP for walk/transit mode, at 9am on 01-19-2-23)\n\ntime travel matrix \\(\\rightarrow\\) using OTP OpenTripPlanner with M Young instructions\n\nfind GTFS data\ndownload OSM data\nbuild graph.obj\n\nsupply data (opportunities / land use / …)\nrun tracc for calculating accessibility to jobs… see basic_accessibility_example_TRACC.ipynb\nrun also for green spaces, as in “minimum travel time to reach n destinations” (see above link)\n\nFeedback The above procedure makes it unclear to understand the results PLUS editing the parameters by own requirements (in particular in creating the TTM), so trying to re-do the same using r5py\n2. r5py + tracc\n\ntime travel matrix –&gt; more editable?? shorter to generate, no need of a graph building\n\nfind GTFS data\ndownload OSM data\nbuild graph.obj? network\n\nsupply data (opportunities / land use / …)\ncalculating accessibility to jobs using tracc\nrun also for green spaces, as in “minimum travel time to reach n destinations” using tracc\n\nNote that the accessibility calculation is not supported in the r5py (see here)\n\nAt the time of this writing, only the computation of travel time matrices has been fully implemented. Over time, r5py will be expanded to incorporate other functionalities from R5.\n\nbut you can run this r5 functionality (and everything that Conveyal does, IE “Conveyal Analysis”) using MongoDB locally: github page\n-STILL NEED TO CHECK THIS OPTION-\n\nTO_DO: (once run the above stuff, first trial with jobs accessibilty)  generalise the procedure above in order to create indicators for accessibility:\n\ninput variables format (table fields, etc)\nunderstand how to edit parameters of time travel matrix and generate more of them\nunderstand how travel time matrix work, as atm it seems to only generate transit mode matrix\nscenarios?"
  },
  {
    "objectID": "notes.html#december",
    "href": "notes.html#december",
    "title": "6  Notes",
    "section": "6.3 December",
    "text": "6.3 December\nHands on code finally?\n\nLet’s start from the indicator of House prices, as it is the only one indicator we have atm that is actual values data, not deterministically defined (see table here).\nAlso greenspace is a possible candidate to start the analysis, for determining a method for accessibility calculation. In this case consider Valhalla.\n\nThe 5 LADs in Tine and Wear (labelled by LAD20NM and LAD20CD), highlighted in gray the major urban areas, bordered in blue the 145 MSOAs\n\nPutting in doubt the use of LUR for what we want to do as we are gonna have aggregated outputs\n\nThis regression-based approach estimates the ambient pollutant concentrations at un-sampled points of interest by considering the relationship between ambient concentrations and several predictor variables selected from the surrounding environment\n\n\nA raster graphic image of the area is generated and intersected with area-level population data to formulate the exposure distribution.\n\nExample of a raster as output of a LUR analysis:\n\nQUESTION: WHY do we want aggregated (MSOAs) outputs? I think it’s because we want to be able to compare among scenarios + (quoting Dani) because SPC data is at MSOAs scale\n\nInputs from call with Federico (14 Dec):\n\njobs posting tracker (ONS ???)\n\nfrom Indeed Hiring Lab (employment website for job listings)\nIn the United Kingdom, they provide:\n\nregional_postings_gb.csv This file contains the % change in seasonally-adjusted postings since February 1, 2020 for total job postings in each region in the UK.\ncity_postings_gb.csv This file contains the % change in seasonally-adjusted postings since February 1, 2020 for total job postings in each city in the UK.\n\n\nBRES (Business Registry and Employment Survey) data\n\nAn employer survey of the number of jobs held, broken down by industry\nestimates at detailed geographical and industrial levels (from country down to LSOA)\n\n\n\nExploratory phase The idea is to plot/visualise/put together a few pieces of information and see how they interact with each other, get ideas on what to do with them.\nSteps:\n\nunderstanding Python VS excel (for house prices data)\nunderstanding Python VS shp (for greenspace data + admin boundaries)\nplot house prices VS greenspace locations\nunderstanding json (valhalla) VS maps/python etc… know nothing\n\n\n6.3.1 House prices indicator\nData processing workflow\n\nSee available datasets for House Price Statistics for Small Areas (HPSSAs) from here: houseprices_available-data_HPSSA.xlsx\nThe tables come in .xls format\nchoose either MSOA or LSOA level:\n\nHPSSA Dataset 2 - Median price paid by MSOA.xls file (September 2022 version); note that this dataset contains also breakdown by house type (detached, semidetached, terraced) and by newly/existing dwellings\nHPSSA Dataset 46 - Median house prices by LSOA.xls file\n\nneed to estrapolate just the tab with the relevant info … \\(\\rightarrow\\) automate this??  “table 1a (all house types)”” = Median price paid by MSOA, England and Wales, year ending Dec 1995 to year ending Mar 2022\nfiltering just the relevant grographies for Tyne and Wear county: \\(\\rightarrow\\) automate this??\n\nMSOAs: list in MSOAs_Tyne-Wear.txt MSOA20CD = MSOA code MSOA20NM = MSOA name\nLSOAs: list in TyneWear_LADs_list.csv filter by Local authority: code LAD20CD = Local authority code name LAD20NM = Local authority name\n\nchoose time … data published quarterly (4 times a year) with all editions back to 1995\n\n\n\n\n6.3.2 Accessibility (… Greenspaces)\n\nremove “private” spaces from the analysis (IE golf clubs)?\ncheck “overlapping” features like pitches/leisure centres/etc within parks\nrouting \\(\\rightarrow\\) Valhalla isochrones\ncensus data\nrelevant layers: public venues (schools, hospitals), green/blue spaces,"
  },
  {
    "objectID": "notes.html#agenda---november-29-tue---in-office",
    "href": "notes.html#agenda---november-29-tue---in-office",
    "title": "6  Notes",
    "section": "6.4 Agenda - November, 29 [Tue] - In office",
    "text": "6.4 Agenda - November, 29 [Tue] - In office\n\nreview of the project (objective, idea…)\ndiscussing the data\n\nsee table in data page\nsee sources below:\n\naccessibility (how to calculate, sources)\nGHG emission (resolution)\nhouse prices (the least concern?)\n\n\ndiscussing methodology\n\n2 processes to generate indicators:\n\nLUR\n_____________ (accessibility)\n\noutput\n\nname"
  },
  {
    "objectID": "notes.html#november",
    "href": "notes.html#november",
    "title": "6  Notes",
    "section": "6.5 November",
    "text": "6.5 November\nNeed to fine-tune things after last talk with Dani (end of October).\nInstead of trying to reproduce carbon.place results, we want to produce a Land Use regression model \\(\\rightarrow\\) LUR\nMAJOR UPDATE - We can’t use a regression model for indicators such as accessibility, where the dataset is derived/generated by us and not coming from “actual” measurement (like is the case for GHG emissions or house prices, for instance). In this case we will need to find another procedure to generate a modelisation. We will then have 2 different procedures to generate the indicators, depending on the type of indicator. Within these two types, we aim at generating anyways a comprehensive methodology accross indicators to assess/analyse the different scenarios.A certain scenario can in fact affect different indicators, for example removing a green area to add a working compound can impact positively jobs accessibility, lowering greenspace accessibility.\n\n\n6.5.1 Project name\nA good name for the project? (acronym*)\nwhat does “demonstrator” stand for, why should we stick to that term?\n\nL(O)UD = Land (:egg:) Use Demonstrator :mega:\ndemoland 🏙\n🥚 and 🐥 … 🍳\n\nLAID = LAnd Use Indicators Demonstrator 🪹\nNEST (?) 🪺\n\nLOUSE = Land (o) USe Explanator  🪲 (‘louse’ is singular for lice)\nDODO 🦤 … just because it’s a nice name\n\n\n\n6.5.2 Variables creation\nWe are searching data for:\n\nthe indicators\nthe variables (land use features) to predict the indicators\n\nIn a first phase we are concentrating on 4 of the indicators (the numbering refers to the Intro list here): 1.a/b. Pollution/emissions 1.c. Green space accessibility 2.b. Jobs accessibility 2.c. House prices Below, some notes for each indicator on the data searching process\n\n1.a/b. Pollution/emissions\nIndicator: GHG emissions\nPredictive variables: no. of trips, distance travelled, mode of transport\n\ndata for GHG emissions (total, IE comprehensive of mobility, housing, etc) is available from gov.uk only at LAD level\n[not relevant] estimated Per Capita Consumption-Based Greenhouse Gas Emissions for UK Lower and Middle Layer Super Output Areas, 2016. Data CollectionKilian, Lena and Owen, Anne and Newing, Andy and Ivanova, Diana (2021).UK Data Service. 10.5255/UKDA-SN-854888\n\n\n1.c. Green space accessibility\nIndicator: Green space accessibility\nPredictive variables: number of access points, areal extention of greenspaces, distance from greenspace (access point)\nDefinition:\n\nproportion of an urban population living within a certain distance from a green space boundary\n\n Van Den Bosch et al., 2016\n\nUGS = Urban Green Space\nsee Issue on GitHub for relevant literature on indicators, definitions, methodology to generate UGS maps\naccessibility is not actual data (like emissions for instance) but it’s itself calculated as an index, so what is the meaning in modeling it?\nhow we calculate the distance to the nearest green space… or the entrance gate (tricky)\nEEA Urban Atlas for UGS data (landcover map) data available here  Download per each metro areas here Method described in WHO Europe 2016 report\n\nEuropean Urban Atlas Class 1.4.1 (vector data code 14100):Green Urban Areas (European Commission, 2011) Minimum mapping resolution 0.25 ha, Minimum width: 10 m Included: • Public green areas for predominantly recreational use such as gardens, zoos, parks, castle parks. • Suburban natural areas that have become and are managed as urban parks. • Forests or green areas extending from the surroundings into urban areas are mapped as green urban areas when at least two sides are bordered by urban areas and structures, and traces of recreational use are visible. Not included: • Private gardens within housing areas • Cemeteries • Buildings within parks, such as castles or museums • Patches of natural vegetation or agricultural areas enclosed by built‐up areas without being managed as green urban areas\n\nNote that several green areas in Newcastle fall under the category “Pasture” (see for example Nuns Moor)\n\nLands that are permanently used (at least 5 years) for fodder production. Includes natural or sown herbaceous species, unimproved or lightly improved meadows and grazed or mechanically harvested meadows. Regular agriculture impact influences the natural development of natural herbaceous species composition.\n\nand allotments fall into “Sports and leisure facilities”\n\n\n\nUK SOURCES\n\nOrdnance Survey Open greenspace map with technical notes here  \\(\\rightarrow \\rightarrow\\) open data!  Advantages:\n\nmore accurate\ncovers England, Scotland, Wales\nhas access points!!\nneed for data cleaning, as many sport facilities/playgrounds are drawn with a separate polygon within the big park they are part of (overlapping features in the shp)\nthe file includes cemeteries AND allottments\n\nNatural England Accessible Natural Green Space Standards in Towns and Cities: A Review and Toolkit for their Implementation (ENRR526)\n\nreview and toolkit\n\nPublic Health England report\n\n… data??\n\nFields in trust Green Space Index\n\ninteractive map\nthey launched GSI in 2019\nthey use OS Open Greenspace Map (above) and ArcGIS\nnot available as open data\n\nAHAH Access to Healthy Assets & Hazards (Dani suggested)\n• A multi-dimensional index developed by the CDRC for Great Britain at LSOA level, contains also access to greenspace (passive) - already calculated\n• … different versions:\nVERSION 3 (2022)\nVERSION 2 (2017) \nVERSION 1 (2016)\n• the current version (3) only gives the ‘passive’ greenspace, in terms of NDVI values (from Sentinel)\n\n\n\nScreenshot from the metadata file (Version 3)\n\n\n where the values range between … and … (that’s the index)\nthough, by the description the “passive” greenspace should be a measure of surface (km2):\n\n\n\nScreenshot from the Version 2 Short Technical Report\n\n\n… see “active” and “passive” greenspace definition below\n• the latest pubblication claims to use OSM data: Daras K., Green M. A., Davies A., Barr B., Singleton A. 2019. Open data on health-related neighbourhood features in Great Britain. Scientific data 6 (1), 107. DOI: 10.1038/s41597-019-0114-6\n\nFrom all the available types of ‘green’ spaces in the OSM data, we selected only areas tagged as public accessible with the following area types: cemetery, common, dog park, scrub, fell, forest, garden, greenfield, golf course, grass, grassland, heath, meadow, nature reserve, orchard, park, pitch, recreation ground, village green, vineyard and wood  … The green space indicator has been defined as an area measure of access to green space available to each postcode that intersect with a 900 meters buffer zone\n\nbut, from this 2019 publication, it looks like they are using the OS dataset (and giving both active and passive access):  Daras, K., Green, MA., Davies, A., Singleton, A., Barr, B. 2019. Access to Healthy Assets and Hazards (AHAH) - Updated version 2017. figshare. Short Technical Report. DOI: 10.6084/m9.figshare.8295842.v1\n\nOpen data from OS on Green spaces was used for preparing two variables related to the distance from the nearest green space (active) and the total green space areas available to each postcode in a range of a 900-meter buffer (passive) before creating LSOA level averages\n\nNote on Active and Passive Green Spaces\n\n‘active’ is based on the distance people have to travel to their nearest greenspace access point conducive to physical activity […] The measure is built up from analysis at the postcode level. Distances from each postcode centroid along road networks to the nearest greenspace access point are calculated. Postcodes are matched to LSOAs and an average is taken to get an LSOA score (mean value).\nThe second greenspace indicator labelled as ‘passive’ is based on the proportion of greenspace within a 900 meter buffer (~15 mins walk) from where people live\n\nthe (assumed?) first version though uses OSM (like described above): Green, M. A., Daras, K., Davies, A., Barr, B. & Singleton, A. 2018. Developing an openly accessible multi-dimensional small area index of ‘Access to Healthy Assets and Hazards’ for Great Britain,  but is aware of OS, from the Appendix:\n\nThere were few open source alternatives (or data that could be shared openly within the terms of their licences) containing similar data during the construction of the indicators and our index. Since then, the Ordnance Survey (OS) have released an open resource of locations of green space (OS Green Space Layer; https://getoutside.ordnancesurvey.co.uk/greenspaces/) . We are currently undertaking a full comparison of OSM and OS to explore the strengths and weaknesses of each data source with the aim of improving our green space metrics, however such an evaluation is beyond the scope of this paper.\n\n• They use Routino open source software https://www.routino.org to identify the shortest path between two locations using the OSM transport network\n\nmeasured the network distance between the population-weighted centroid of each postcode in the National Statistics Postcode Lookup (NSPL) and the coordinates of the nearest service (e.g. a population-weighted centroid of postcode for off-license)\n\ncode here\nConclusions:\n\nnot enough METADATA to be able to understand what to use (missing field names)\nnot clear which data source they use in which version (NDVI, OS, OSM?)\nonly passive accessibility available in last version\n\nWRITE TO THE TEAM detailed list of questions\n\n\n\n2.b. Jobs accessibility\nIndicator: accessibility to jobs (measured/calculated)\nPredictive variables: working population, n. of available jobs\n\naccessibility is not actual data (like emissions for instance) but it’s itself calculated as an index, so what is the meaning in modeling it?\nQUANT map - how is it calculated - how to download it … format, etc\nAccessibility Destination Datasets see paragraph below\n\n\n2.c. House prices\nIndicator: house price (avg / zonal effect / dimension / amenities ???)\nPredictive variables: dwellings availability, services, accessibility to PT\n\nwhat scenario on house prices?\ngov.uk data most recent source: House price statistics for small areas in England and Wales: year ending March 2022\n\nDifferences to other house price statistics:\n\nThere are two sets of official statistics for house prices. In addition to these HPSSAs, the Office for National Statistics (ONS) also produces the UK House Price Index (UK HPI). The HPSSAs measure the number of property transactions and the price paid for properties sold in a given period, while the UK HPI measures the changing value of properties in the housing market. You can find out more about the differences and uses of these outputs in our House price statistics for small areas Quality and Methodology Information (QMI).\n\n\navailable at MSOA level:\n\n\n\n\n\n\n\n\n\nDataset No.\nDataset Name\nPeriodicity\n\n\n\n\nHPSSA dataset 1\nNumber of sales of residential properties for middle layer super output areas\nQuarterly\n\n\nHPSSA dataset 2\nMedian price paid for middle layer super output areas\nQuarterly\n\n\nHPSSA dataset 3\nMean house prices for middle layer super output areas\nQuarterly\n\n\nHPSSA dataset 4\nLower quartile house prices for middle layer super output areas\nAnnually\n\n\nHPSSA dataset 5\nTenth percentile house prices for middle layer super output areas\nQuarterly\n\n\n\n\n6.5.2.1 Accessibility data\nUPDATE\nIt seems that from 2014 the same type of data is released as Journeytime Statistics\nwith the list of tables available here\nNEED TO CHECK if they give also number of people, that seems missing in the new data format. For example the variable:\n\n\n\nAll20_PT/walk\nEMPLO049\nUsers within 20 minutes by PT/walk\n\n\n\ndoes not appear in the new tables, though, we have the total population (Empl_pop) AND the percentage of population per each mode of transport + time, for example (for table 0501):\n\n\n\n\n\n\n\n\nField\nAlternate name\nDescription\n\n\n\n\n100EmpPT15pct\nEmp106\n% users within 15 minutes of employment centres with 100 to 499 jobs available by PT/walk\n\n\n100EmpPT30pct\nEmp107\n% users within 30 minutes of employment centres with 100 to 499 jobs available by PT/walk\n\n\n100EmpPT45pct\nEmp108\n% users within 45 minutes of employment centres with 100 to 499 jobs available by PT/walk\n\n\n100EmpPT60pct\nEmp109\n% users within 60 minutes of employment centres with 100 to 499 jobs available by PT/walk\n\n\n\n… from which we could infer the variable above? \n\nSome useful and valuable datasets on accessibility by several means of transport was (apparently?) available from DFT until 2012, in csv format. After some strenuous research managed to find the archive for it here.\nAccessibility Destination Datasets\n\nthey measure accessibility to key services like:\n\nfood stores\neducation\nhealth care\ntown centres\nemployment centres\n\npublished for England at national, regional, LAD and LSOA level.\nhave they been substited by Journey time statistics data?\n\nNote data at LSOA level is also available in gov.uk in xls format\nwhere also 2013 is included!\n\nExcel datasets containing raw destination data for calculating Accessibility statistics. This gives the locations of the different services used within these calculations: Primary schools, Secondary Schools, Further Education, Hospitals, GPs, Town Centres, Employment Centres\n\nthese makes up to 8 tables of accessibility:\n\nscreenshot (from gov.uk webpage) of some of the the available tables\nAccessibility Statistics Guidance 2014\n\n\n\n6.5.3 Theoretical framework\nIn a general (non-linear/linear) regression model we have a given dependent variable which we try to explain by several independent/explanatory variables.  In our case for a LUR model we have, considering for example GHG emissions from mobility or housing:\n\n\n\n\n\n\n\n\nDependent variable\nactual data for GHG emissions\n\n\n\nExplanatory variables\nlanduse variables\n(ex. n. of trips, distance,  mode of transport…)\n\n\n\n\nFormulas here \n\n\n\n6.5.4 Some literature on LUR\nQuestions\n\nLUR is generally used for air quality prediction  …FIND examples of non-air pollutants applications?\nLUR potential predictor variables extraction … relevant for us? (limited number of variables) \\(\\rightarrow\\) ideally we’d like to perform this as well\nLUR output is raster VS vectorial \\(\\rightarrow\\) we’ll need to aggregate the data at some spatial level (MSOAs for instance), introducing some level of approximation\nnot clear how the spatial connotation enters the model, just because we use data defined at (some) geographic level? YES\n\n\n\nhttps://en.wikipedia.org/wiki/Land_use_regression_model\n\nA raster graphic image of the area is generated and intersected with area-level population data to formulate the exposure distribution.\n\nHoek et al., 2008 “A review of land-use regression models to assess spatial variation of outdoor air pollution”  They review 25 land-use regression studies.\n\nApplication of the land-use regression approach for air pollution mapping was introduced in the SAVIAH (Small Area Variations In Air quality and Health) study (Briggs et al., 1997). The technique was initially termed regression mapping\n\n\nLand-use regression combines monitoring of air pollution at typically 20–100 locations, spread over the study area, and development of stochastic models using predictor variables usually obtained through geographic information systems (GIS)\n\n\nmain components of LUR: monitoring data, geographic predictors and model development and validation\n\nBertazzon et al., 2015 “Accounting for spatial effects in land use regression for urban air pollution modeling”\n\n\nLUR models are described by standard regression equations. Over the past decade, land use regression (LUR) modeling has emerged as a preferred method for assessing exposure to spatially heterogeneous pollutants, including NO2 (Health Effects Institute, 2010). Despite their advantages, LUR models rely on spatial data; therefore, they are subject to the spatial effects associated with the properties of these data.\n\n\nMorley and Gulliber, 2018“A land use regression variable generation, modelling and prediction tool for air pollution exposure assessment”\n\nRLUR software to develop LUR model in R; Open-source code available in GitHub; GUI with visualisation tools\n\nMa et al. 2020 “PyLUR: efficient software for land use regression modelling the spatial distribution of air pollutants using GDAL/OGR library in Python”\n\n\nAlthough conceptually quite simple, its successful implementation requires detailed knowledge of the area, expertise in GIS, statistics, and programming skills, which makes this modelling approach relatively inaccessible to novice users.\n\n\nPyLUR out-performs RLUR for modelling in the Bradford and Auckland case studies examined. Furthermore, PyLUR is much more efficient in data processing and it has a capability to handle detailed GIS input data.\n\n\nThe principles of LUR modelling can be summarized in five steps. First, air pollution monitoring and GIS data are collected within the scope of the study area. Secondly, different kinds of potential predictor variables for each site are generated using GIS buffering or other geospatial analysis methods. Thirdly, multiple regression analysis is carried out to develop one regression equation establishing the relationship between the observed air pollutant concentrations and significant predictor variables selected from a pool of all potential predictor variables. Fourthly, model performance is evaluated using holdout or cross-validation. **Finally*, once the model is successfully validated, it can be applied to predict the concentration at un-sampled points of interest or generate an air pollutant concentration map of the whole study area (Morley and Gulliver, 2018).\n\n\nMolter and Lindley, 2021 “Developing land use regression models for environmental science research using the XLUR tool – More than a one-trick pony”\n\n\nA Python toolbox for ArcGIS Pro that enables the development and application of land use regression models\n\n… relevant for literature (it’s developed for ArcGIS, so no use)\n\n\n6.5.5 LUR in Python\n\ncheck out this blog How to Build a Regression Model in Python\nGeographic Data Science with Python, book Chap. 11, Spatial Regression\nPaper PyLUR: Efficient software for land use regression modeling the spatial distribution of air pollutants using GDAL/OGR library in Python  Note the code is available online on ResearchGate here (find “linked data” tab)\n\n\n\n6.5.6 Facts on GHG emissions\nGovernmental report UK local authority and regional greenhouse gas emissions national statistics, 2005 to 2020"
  },
  {
    "objectID": "notes.html#october",
    "href": "notes.html#october",
    "title": "6  Notes",
    "section": "6.6 October",
    "text": "6.6 October\nInitial trials\nWorking on a. mobility based emissions \\(\\rightarrow\\) IE transport data\n&\nBuilding base scenario\nRoadmap:\n\nTry to dl/open/visualise SPC data \\(\\rightarrow\\) Note: study case Metropolitan county of Tyne and Wear\nInvestigate potentially relevant data from UK Data Services data \\(\\rightarrow\\) any other relevant dataset?\nHow to connect/integrate TUS to SPC dataset – why?\nvisualise the integrated dataset \\(\\rightarrow\\) base scenario\nthink “future scenarios”\n\n The 5 LADs in the Metropolitan County of Tyne and Wear, highlighted are also the 4 major town areas\n\nKeep in mind when you’ll “generalise” the procedure\nIE pass from the study case to a national case\n\nhow to select MSOAs for Origin and Destination from the dataset (take off abroad destinations as well)\n\n\n\n\n6.6.1 Defining relations\nWe can see the Indicators \\(I_{i}\\), with \\(i = \\{1, ..., n\\}\\), as a function of different land uses \\(l_{j}\\) where \\(j = \\{1, ..., k\\}\\) and \\(I_{i}\\) can be expressed as generic mathematical relation (that we express with the symbol “\\(\\star\\)”“) between several \\(l_{j}\\) weighted by \\(k\\) generic weights/parameters \\(w_{j}\\), as follows:\n\\[I_{i}(l) = w_1^il_{1} \\star  w_2^il_{2} \\dots \\star w_k^il_{k}\\]\nDifferent indicators can depend on same landuse variables, and per each indicator the scenarios can be expressed by acting on the paramters \\(w_{j}\\).\nAs an example, using the definition above the indicator Mobility based emissions (a.) could be expressed for commuting trips per mode of transport and per each MSOA as:\n\n\\[\n\\begin{align}\n[\\textit{emissions/msoa/year}] & =  w_1[trips/day] \\star\\\\\n& \\star  w_2[distance/trip] \\star\\\\\n& \\star  w_3[n\\_individuals] \\star\\\\\n& \\star  w_4[\\textit{n of commuting days/year}] \\star \\\\\n& \\star w_5[\\textit{CO}_2 \\textit{k}]\n\\end{align}\n\\]\nwhere:\n\n\\([trips/day]\\) is a fixed value (average per person from DFT data … *)\n\\([distance/trip]\\) is calculated as shortest distance between the MSOAs’ centroids\n\\([n\\_individuals]\\) is given by the UK Census 2011 commuting flow\n\\([\\textit{n of commuting days/year}]\\) is a fixed value (average per person from DFT data … *)\n\\([CO_2 k]\\) is the carbon dioxide equivalent emission factor per mode of transport\n\n\n\n6.6.2 Working questions:\n\nwhich year to take into consideration for the analysis? (Census, conversion factors, surveys…)\nwhen I calculate the distance home-place of work, how do I consider the intraMSOA trips (IE within the same MSOA), as I am only taking into account the centroids of the MSOAs?\nhow we count total number of people (age, people working)\ndo we give the results per capita (then see point above) or total per MSOA\nhow many hours for the working from home people (not counting for now, as not using transport)\n\n\n\n\n6.6.3 Approximations\n\nonly OD within MSOAs of this county\nconsidering as distance only the pop weighted centroids for each MSOA\nLondon has specific values for CO2 conversion factors (ex for cabs, buses, underground) but only using general values (correct later if needed for London case)\n…\n\n\nCommuting is really just one part of the total travels by car per per person per year:\n source: national travel survey\n… it sounds then reductive to consider only commuting trips for emissions!\n\n\n\n6.6.4 Python code\nNote: first trials in R, as I am more confident with the language, and trying to reproduce the code from carbun calculator for prep_travel_to_work.R,\nwill then translate to Python\n\nRemember to add in READ_ME a walkthrough.\nUsing env.yml \\(\\dots\\) use conda or poetry?\n\n\n\n6.6.5 Preliminary results\nOrigin Destination flows of individuals for commuting to work (2011 UK Census data), the Metropolitan County of Tyne and Wear, separated by mode of transport \nPreliminary results for GHG emissions from cars, total per MSOA per year in Tyne and Wear"
  },
  {
    "objectID": "notes.html#september",
    "href": "notes.html#september",
    "title": "6  Notes",
    "section": "6.7 September",
    "text": "6.7 September\nExploratory phase\nThe idea is to focus on a few indicators (one or two) in order generate a methodology to apply to different variables (IE all the rest of indicators)\nConcentrating on Indicators for Net-zero a and b:\n\n\nmobility based emissions … integration with SPC \\(/\\) AB-street?\n\n\nhousing based emissions\n\n\n\n6.7.1 Data availability\n\n\n(aggregated at LAD level) UK GHG emissions national statistics, estimates per Local Authority Data for 2005 - 2020 \\(\\rightarrow\\) this datum is a sum of emissions from 2005-2020\n\n\n\n6.7.1.1 a. mobility based emissions\n\nwe can get from gov.uk CO2e (carbon dioxide equivalent) emissions factors for several occupations and travel modes, including transport, freight, etc link;&lt;br&gt; We get the emission factors per mode of transport from the tab “Business travel-land” and “homeworking” (for working from home individuals)\nOD flows from UK census … only to work and home? check source \\(\\rightarrow\\) YES \\(\\Downarrow\\)\nget travel to school flow data from Propensity to Cycle Tool PCT?\nLocation of usual residence and place of work by method of travel to work (…origin destination flows) table WU03UK](https://wicid.ukdataservice.ac.uk/cider/wicid/downloads.php) at LAD level\nNote: can download all the tables for “Location of usual residence and place of work by method of travel to work” at different levels (LAD to LSOA, though the lattest is not Open data) here https://wicid.ukdataservice.ac.uk/cider/about/data_int.php?type=2 &lt;br&gt; safeguarded data!! git sttuslet’s find MSOA data: &lt;br&gt; nomisweb\n\n\nWU03BEW(with ‘outside UK’ detailed) safeguarded\nWU03EW (with ‘outside UK’ collapsed) open\n\n\n\n\n6.7.1.2 b. housing based emissions\nSub-national electricity and gas consumption data, overview link\n\nelectricity consumption:\n\n\none table per year (20105 to 2020) of total consumption at region and LAD levels link\none table per year (2010 to 2020) of total consumption at LSOA or MSOA level link\nelectricity and gas consumption (kWh) at postcode level (England, Scotland, Wales), one table per year, 2013,2015-2020 Experimental\nelectricity consumption data for 2005 to 2020 as a single table, with years stacked one above the other stacked data\n\n\nanalogous links for gas consumption\n\n\n\n\n6.7.1.3 People behavior\nPeople behavior and time use from The UK Time Diary Study 2014 - 2015 - UK Time Use Survey carried by NatCen and available from UK Data Service\nwhat we can get from this source: time people spend in different activities, mode of transport (yes?)\n\n\n\n6.7.2 Did someone already do this?\ncarbon.place\nProject from Malcom Morgan (Univ of Leeds) …\n\nThe PBCC estimates the average carbon footprint per person for each LSOA in England\n\nNOTE:\ncool project, GitHub code available but not reproducible (?)\nopened issue here https://github.com/creds2/CarbonCalculator/issues/6"
  },
  {
    "objectID": "notes.html#open-general-questions",
    "href": "notes.html#open-general-questions",
    "title": "6  Notes",
    "section": "6.8 Open general questions",
    "text": "6.8 Open general questions\nAnd plausible answer\n\nimportance of localised emissions and need for air-flow modelling … not relevant for GHG\nwhat is the Research Question \\(\\rightarrow\\) What are the “best” values in the parametrisation of the land use variables? Could we train the computer to predict these values?\nResolution LSOAS/ MSOAS ? feedback from Dani regarding SS: SS gives conversion to LSOAs \\(\\Downarrow\\)\nhow to generate scenarios - ideas: change parameters’ range/values, run ABstreet simulations…?\nintegrate with SPC - need to integrate more Census variables? feasible?\nUse SPC (individuals’ level data) as we aggregate at MSOA level… what variables are meaningful when aggregated?\ncan we actually build a methodology, given the different range of indicators and data?\nhow turn on/off scenarios in the visualisation- different layers in the map\ntype of output - map, web … MapBox MapLibre GL, Leaflet, …\n\n\n\n6.8.1 Output / map generation\nNote: could generate a website via MapLibre, checked the options\n\n\n\nSuggested data sources:\n\nSPC - Synthetic Population Catalyst website\nSS - Spatial Signature website\nboth\n\nIndicators are grouped into 4 general themes to reflect the goals of the National Land Development Programme (NLDP) in relation to the environment, economy, infrastructure and society:\n\n\n6.8.2 Net-zero\n\nMobility-based emissions (e.g., trips x distance x mode —&gt; CO2)\nHousing-based emissions (e.g., CO2 emissions from building energy consumption)\nGreen space (area, access, fragmentation)\n\n\n\n6.8.3 Economy\n\nDistance to nearest job (by industry)\nJob volume within accessible distance\nAvailability of (appropriate) housing stock\n\n\n\n6.8.4 Infrastructure stock (vacancy)\n\nBrownfield areas\nVacant lots and properties\nTransport networks and connectivity\n\n\n\n6.8.5 Society and Health\n\nPhysical health\nMental health\nHealthy living and lifestyles\n\nThe page Data Sources will be updated once the sources are determined and actually used in the analysis."
  },
  {
    "objectID": "notes.html#scenarios-building",
    "href": "notes.html#scenarios-building",
    "title": "6  Notes",
    "section": "6.9 Scenarios building",
    "text": "6.9 Scenarios building\nThe existing baseline will be modified through indicative scenarios of relevance, underlining the ability of the modelling system to illustrate the trade-offs between competing objectives through evaluation of the key indicators.\nScenarios will be generated as:\n\nType I what if? scenarios: the consequence of a range of concrete actions (e.g. construct a new tram line);\nType II what could be? scenarios: to explore more aspirational targets (e.g. reduce emissions by 10%)\n\nAlthough the final set of scenarios will be co-produced with the partners, an illustration is provided below:\n\nInfrastructure scenarios:\n\nS1A – Add new jobs through significant inward investment (e.g., construction of Government offices/public buildings) - Type I\nS1B – reorient to new mobility targets through modal shift (increased pedestrian and public transport) - Type II\nS1C – Increase access to jobs (e.g., more roads/transit/cycle lanes) - Type I or II\n\nEnvironmental scenarios:\n\nS2A – create a new urban park or nature reserve - Type I\nS2B – design a future urban space with net zero emissions - Type II\n\nHousing stock:\n\nRetrofit existing neighbourhoods to increase density/decrease sprawl - Type I or II"
  },
  {
    "objectID": "notes.html#data-sources",
    "href": "notes.html#data-sources",
    "title": "6  Notes",
    "section": "6.10 Data Sources",
    "text": "6.10 Data Sources\n\n6.10.1 Comprehensive tables\nTable 1 -  4 indicators and data we use to quantify them:\n\n\n\nactual (X) VS estimated (O)\nIndicator\nDefinition\nData source\nLink\n\n\n\n\nO\nMobility emissions\n\ngov uk data estimates at LAD level (only)\n\n\n\nX\nAir pollution hazard\n\nLocal Authority + European data\n\n\n\nO\nGreenspace accessibility\n\nOS greenspace layer\nlink\n\n\nO\nJobs accessibility\nn. jobs within certain time interval by transport mode\nto be created\n\n\n\nX\nHouse prices\nMedian house prices for administrative geographies\nONS\n2022 data\n\n\n\n\nTable 2 -  Indicators (columns) and plausible explanatory/building variables (rows - landuse variables)\n\n\n\n\n\n\n\n\n\n\n\nVariables\nMobility emissions\nGreenspace acc\nJobs acc\nHouse prices\nSources\n\n\n\n\nn. of trips\nX\n\n\n\nOD data (Nomis)\n\n\ndistance\nX\n\n\n\nOD data (Nomis)\n\n\nmode transport\nX\n\n\n\nOD data (Nomis)\n\n\ndistance to access point\n\nX\n\nX\nfrom OS layer\n\n\nareal extension of gs\n\nX\n\nX\nfrom OS layer\n\n\nn. available jobs\n\n\nX\nX\nNomis BRES\n\n\ndistance to employment center\n\n\nX\ngenerated\n\n\n\naccess to public transport\n\n\nX\ngenerated\n\n\n\n\n… distinguish landuse as explanatory variable from landuse as indicator…\n\n\n6.10.2 List of sources\nData hunting still in progress, to be filled up when data use is certain. See notes to follow the development.\n\n6.10.2.1 Time Use Survey\nTime Use Survey for UK is available from UK Data Service website at http://dx.doi.org/10.5255/UKDA-SN-8128-1"
  }
]