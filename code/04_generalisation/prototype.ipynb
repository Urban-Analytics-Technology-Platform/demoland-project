{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from itertools import product\n",
    "import datetime as dt\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "\n",
    "from r5py import TransportNetwork, TravelTimeMatrixComputer, TransportMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the extent of AoI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.read_file(\"https://github.com/Urban-Analytics-Technology-Platform/demoland-web/raw/main/web/src/data/geography.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_poly = aoi.to_crs(27700).unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get H3 grid with the data for the AoI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = \"../../../demoland_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the full grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = gpd.read_parquet(f\"{data_folder}/h3/grid_complete.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a portion of the grid covering AoI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_aoi = grid.iloc[grid.sindex.query(aoi_poly, predicate=\"intersects\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Make predictive models ready\n",
    "\n",
    "    - to be done once the final models are settled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Make accessibility ready\n",
    "    6. Get GTFS\n",
    "  \n",
    "Go to https://data.bus-data.dft.gov.uk/downloads/, register and download timetable data for your region in GTFS data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfs_data_file = f\"{data_folder}/raw/accessibility/itm_north_east_gtfs.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Get network from OSM\n",
    "\n",
    "Download a fresh OSM snapshot for England."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://download.geofabrik.de/europe/united-kingdom/england-latest.osm.pbf')\n",
    "with open(\"england-latest.osm.pbf\", \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the AoI. We need a GeoJSON of the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi.dissolve().to_file(\"aoi.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then can use osmium to get an extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================================================] 100% \n"
     ]
    }
   ],
   "source": [
    "!osmium extract -p aoi.geojson england-latest.osm.pbf -o aoi.osm.pbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Get OS Greenspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.os.uk/downloads/v1/products/OpenGreenspace/downloads?area=GB&format=GeoPackage&redirect')\n",
    "with open(\"opgrsp_gpkg_gb.zip\", \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/mambaforge/envs/shap/lib/python3.11/site-packages/pyogrio/raw.py:194: RuntimeWarning: File /vsimem/e27ecc0b3d7047ce9b7df4c11a0f0c2c has GPKG application_id, but non conformant file extension\n",
      "  result = ogr_read(\n",
      "/home/martin/mambaforge/envs/shap/lib/python3.11/site-packages/pyogrio/raw.py:194: RuntimeWarning: File /vsimem/18929c422c094f15838bdfad8bd472fc has GPKG application_id, but non conformant file extension\n",
      "  result = ogr_read(\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('opgrsp_gpkg_gb.zip', 'r') as zip_ref:\n",
    "    with zip_ref.open(\"Data/opgrsp_gb.gpkg\") as gsp:\n",
    "        f = gsp.read()\n",
    "        greenspace_sites = gpd.read_file(f, engine=\"pyogrio\", layer=\"greenspace_site\")\n",
    "        greenspace_access = gpd.read_file(f, engine=\"pyogrio\", layer=\"access_point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the AoI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenspace_sites_aoi = greenspace_sites.iloc[greenspace_sites.sindex.query(aoi_poly, predicate=\"intersects\")]\n",
    "greenspace_access_aoi = greenspace_access.iloc[greenspace_access.sindex.query(aoi_poly, predicate=\"intersects\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Process OS Greenspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenspace_sites_select = greenspace_sites_aoi.query(\n",
    "    \"function!='Allotments Or Community Growing Spaces' & function!='Golf Course' & function!='Bowling Green'\"\n",
    ")\n",
    "publicpark = greenspace_sites_select.query(\"function=='Public Park Or Garden'\")\n",
    "playingfield = greenspace_sites_select.query(\"function=='Playing Field'\")\n",
    "othersport = greenspace_sites_select.query(\"function=='Other Sports Facility'\")\n",
    "therest = greenspace_sites_select.query(\n",
    "    \"function!='Playing Field' & function!='Public Park Or Garden' & function!='Other Sports Facility'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 'therest' not included in the upper categories\n",
    "# we use sjoin to performe a spatial filter of 'therest' polygons contained in upper categories\n",
    "join11 = gpd.sjoin(therest, othersport, predicate=\"within\", how=\"inner\")\n",
    "join12 = gpd.sjoin(therest, playingfield, predicate=\"within\", how=\"inner\")\n",
    "join13 = gpd.sjoin(therest, publicpark, predicate=\"within\", how=\"inner\")\n",
    "\n",
    "# generate list of the IDs of 'therest' contained in upper categories, in order to eliminate the corresponding polygons from the layer\n",
    "list_for_diff11 = join11[\"id_left\"].drop_duplicates().to_list()\n",
    "\n",
    "diff11 = therest[\n",
    "    ~therest.id.isin(list_for_diff11)\n",
    "]  # 1st difference layer # note the negation character ~ to take the polygons NOT included\n",
    "\n",
    "list_for_diff12 = join12[\"id_left\"].drop_duplicates().to_list()\n",
    "diff12 = diff11[~diff11.id.isin(list_for_diff12)]  # 2nd difference layer\n",
    "\n",
    "list_for_diff13 = join13[\"id_left\"].drop_duplicates().to_list()\n",
    "diff13 = diff12[\n",
    "    ~diff12.id.isin(list_for_diff13)\n",
    "]  # 3rd difference layer, this is for 'therest' categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat the same operation for subsequent categories:\n",
    "# find 'othersport' not included in the upper categories\n",
    "join21 = gpd.sjoin(othersport, playingfield, predicate=\"within\", how=\"inner\")\n",
    "join22 = gpd.sjoin(othersport, publicpark, predicate=\"within\", how=\"inner\")\n",
    "\n",
    "list_for_diff21 = join21[\"id_left\"].drop_duplicates().to_list()\n",
    "diff21 = othersport[~othersport.id.isin(list_for_diff21)]\n",
    "\n",
    "list_for_diff22 = join22[\"id_left\"].drop_duplicates().to_list()\n",
    "diff22 = diff21[~diff21.id.isin(list_for_diff22)]  # 'othersport' difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 'playing fields' not included in the upper categories (and viceversa?)\n",
    "join31 = gpd.sjoin(playingfield, publicpark, predicate=\"within\", how=\"inner\")\n",
    "join32 = gpd.sjoin(\n",
    "    publicpark, playingfield, predicate=\"within\", how=\"inner\"\n",
    ")  ## check it is not empty ... it is empty, we do not use this join\n",
    "\n",
    "list_for_diff31 = join31[\"id_left\"].drop_duplicates().to_list()\n",
    "diff31 = playingfield[\n",
    "    ~playingfield.id.isin(list_for_diff31)\n",
    "]  # 'playingfield' difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together all the differences layers: (and should bring out to the desired output)\n",
    "together1 = pd.concat([diff13, diff22]).pipe(\n",
    "    gpd.GeoDataFrame\n",
    ")  # 'therest' + 'othersport' differences\n",
    "together1.head()\n",
    "together2 = pd.concat([together1, diff31]).pipe(\n",
    "    gpd.GeoDataFrame\n",
    ")  # last gdf + 'playingfield' difference\n",
    "together_again = gpd.GeoDataFrame(pd.concat([together2, publicpark]), crs=27700)  # last gdf + all the public parks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_gs_id = together_again[\"id\"].to_list()\n",
    "accesspoints_edge = greenspace_access_aoi[greenspace_access_aoi.ref_to_greenspace_site.isin(list_gs_id)]\n",
    "accesspoints_edge = accesspoints_edge.to_crs(27700)\n",
    "\n",
    "together_again[\"area_m2\"] = together_again[\"geometry\"].area\n",
    "\n",
    "together_again.to_file(\"greenspace.gpkg\", layer=\"sites\")\n",
    "accesspoints_edge.to_file(\"greenspace.gpkg\", layer=\"access_points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create traveltime matrix (origins are cells, destinations are cells plus greenspace entrances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = grid_aoi.set_geometry(grid_aoi.centroid).to_crs(4326)\n",
    "origins[\"id\"] = origins.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = pd.concat(\n",
    "    [\n",
    "        origins[[\"id\", \"geometry\"]],\n",
    "        accesspoints_edge[[\"id\", \"geometry\", \"ref_to_greenspace_site\"]].to_crs(4326),\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_network = TransportNetwork(\"aoi.osm.pbf\", [gtfs_data_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate dataframe with all from_id and all to_id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = product(origins[\"id\"].unique(), destinations[\"id\"].unique())\n",
    "empty_ttm = pd.DataFrame(prod)\n",
    "empty_ttm.columns = [\"from_id\", \"to_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables\n",
    "date_time = \"2023,11,23,9,30\"  # CHOOSE BEST DATE/TIME\n",
    "max_time = dt.timedelta(seconds=900) # SET TO 15 MIN\n",
    "walking_speed = 4.8\n",
    "cycling_speed = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe to match legmode and transitmode objects (to be inputted in the ttm computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_lut = pd.DataFrame(\n",
    "    [\n",
    "        [\"transit\", TransportMode.CAR, TransportMode.WALK],\n",
    "        [\"car\", \"\", TransportMode.CAR],\n",
    "        [\"bicycle\", \"\", TransportMode.BICYCLE],\n",
    "        [\"walk\", \"\", TransportMode.WALK],\n",
    "    ],\n",
    "    columns=(\"Mode\", \"Transit_mode\", \"Leg_mode\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate custom list of transit+transport mode for the parameter transport_modes in TravelTimeMatrixComputer\n",
    "def list_making(s, z):\n",
    "    if s:\n",
    "        return [s] + [z]\n",
    "    return [z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current mode is: transit , transit is: TransportMode.CAR , transport var is: [<TransportMode.CAR: 'CAR'>, <TransportMode.WALK: 'WALK'>]\n",
      "finished calculating ttm for mode transit\n",
      "Duration for transit : 0:09:07.266543\n",
      "The current mode is: car , transit is:  , transport var is: [<TransportMode.CAR: 'CAR'>]\n",
      "finished calculating ttm for mode car\n",
      "Duration for car : 0:08:44.851404\n",
      "The current mode is: bicycle , transit is:  , transport var is: [<TransportMode.BICYCLE: 'BICYCLE'>]\n",
      "finished calculating ttm for mode bicycle\n",
      "Duration for bicycle : 0:09:46.095740\n",
      "The current mode is: walk , transit is:  , transport var is: [<TransportMode.WALK: 'WALK'>]\n",
      "finished calculating ttm for mode walk\n",
      "Duration for walk : 0:10:16.975145\n"
     ]
    }
   ],
   "source": [
    "ttm_complete = empty_ttm.copy()\n",
    "\n",
    "# loop to compute a ttm for all the modes and generate one single ttm table in output\n",
    "for row in modes_lut.itertuples():\n",
    "    start_time = dt.datetime.now()\n",
    "    mode = row.Mode\n",
    "    transit_mode = row.Transit_mode\n",
    "    leg_mode = row.Leg_mode\n",
    "    transport_mode = list_making(\n",
    "        transit_mode, leg_mode\n",
    "    )  # creating list of objects for transport_modes parameter\n",
    "\n",
    "    print(\n",
    "        \"The current mode is:\",\n",
    "        mode,\n",
    "        \", transit is:\",\n",
    "        transit_mode,\n",
    "        \", transport var is:\",\n",
    "        transport_mode,\n",
    "    )\n",
    "    ttm_computer = TravelTimeMatrixComputer(\n",
    "        transport_network,\n",
    "        origins=origins,\n",
    "        destinations=destinations,\n",
    "        departure=dt.datetime.strptime(date_time, \"%Y,%m,%d,%H,%M\"),\n",
    "        max_time = max_time,\n",
    "        speed_walking=walking_speed,\n",
    "        speed_cycling=cycling_speed,\n",
    "        transport_modes=transport_mode,\n",
    "    )\n",
    "\n",
    "    ttm = ttm_computer.compute_travel_times()\n",
    "    ttm = ttm.rename(\n",
    "        columns={\"travel_time\": f\"time_{mode}\"}\n",
    "    )  # renaming 'travel_time' column (automatically generated) to 'time_{mode of transport}'\n",
    "    #  merging the empty table generated before (with all possible origins and destinations) with the ttm, per each mode adding a travel time column\n",
    "    ttm_complete = ttm_complete.merge(\n",
    "        ttm, how=\"outer\", left_on=[\"from_id\", \"to_id\"], right_on=[\"from_id\", \"to_id\"]\n",
    "    )\n",
    "\n",
    "    print(\"finished calculating ttm for mode\", mode)\n",
    "    end_time = dt.datetime.now()\n",
    "    print(\"Duration for\", mode, \": {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm_complete.to_parquet(f\"ttm_complete.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>to_id</th>\n",
       "      <th>time_transit</th>\n",
       "      <th>time_car</th>\n",
       "      <th>time_bicycle</th>\n",
       "      <th>time_walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8919465366bffff</td>\n",
       "      <td>8919465366bffff</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8919465366bffff</td>\n",
       "      <td>89194653477ffff</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8919465366bffff</td>\n",
       "      <td>8919465343bffff</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8919465366bffff</td>\n",
       "      <td>8919465340fffff</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8919465366bffff</td>\n",
       "      <td>89194653433ffff</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66781104</th>\n",
       "      <td>89197331847ffff</td>\n",
       "      <td>C8E183F0-C82B-4201-A71C-958A5A955BBB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66781105</th>\n",
       "      <td>89197331847ffff</td>\n",
       "      <td>D1D57228-E4C4-42A9-A214-B98878AF0D73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66781106</th>\n",
       "      <td>89197331847ffff</td>\n",
       "      <td>575DF9E9-3BB7-4ED4-9550-3D7812C75BF0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66781107</th>\n",
       "      <td>89197331847ffff</td>\n",
       "      <td>C9803849-2A52-484C-ABF7-8A0C4043FD23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66781108</th>\n",
       "      <td>89197331847ffff</td>\n",
       "      <td>D1161639-3870-4CDF-8275-4F521148BB83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66781109 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  from_id                                 to_id  time_transit  \\\n",
       "0         8919465366bffff                       8919465366bffff           0.0   \n",
       "1         8919465366bffff                       89194653477ffff          16.0   \n",
       "2         8919465366bffff                       8919465343bffff          16.0   \n",
       "3         8919465366bffff                       8919465340fffff          14.0   \n",
       "4         8919465366bffff                       89194653433ffff          15.0   \n",
       "...                   ...                                   ...           ...   \n",
       "66781104  89197331847ffff  C8E183F0-C82B-4201-A71C-958A5A955BBB           NaN   \n",
       "66781105  89197331847ffff  D1D57228-E4C4-42A9-A214-B98878AF0D73           NaN   \n",
       "66781106  89197331847ffff  575DF9E9-3BB7-4ED4-9550-3D7812C75BF0           NaN   \n",
       "66781107  89197331847ffff  C9803849-2A52-484C-ABF7-8A0C4043FD23           NaN   \n",
       "66781108  89197331847ffff  D1161639-3870-4CDF-8275-4F521148BB83           NaN   \n",
       "\n",
       "          time_car  time_bicycle  time_walk  \n",
       "0              4.0           5.0        0.0  \n",
       "1             16.0           NaN        NaN  \n",
       "2             16.0           NaN        NaN  \n",
       "3             14.0           NaN        NaN  \n",
       "4             15.0           NaN        NaN  \n",
       "...            ...           ...        ...  \n",
       "66781104       NaN           NaN        NaN  \n",
       "66781105       NaN           NaN        NaN  \n",
       "66781106       NaN           NaN        NaN  \n",
       "66781107       NaN           NaN        NaN  \n",
       "66781108       NaN           NaN        NaN  \n",
       "\n",
       "[66781109 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttm_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
