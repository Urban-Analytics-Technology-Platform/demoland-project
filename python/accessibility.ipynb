{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive accessibility script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Variables definition and data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime as dt\n",
    "import tracc\n",
    "from r5py import TransportNetwork, TravelTimeMatrixComputer, TransitMode, LegMode\n",
    "from datetime import datetime,date,timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product # needed for generating all combinations of O-D pairs\n",
    "sys.argv.append([\"--max-memory\", \"8G\"])\n",
    "\n",
    "\n",
    "data_folder = \"/Users/azanchetta/OneDrive - The Alan Turing Institute/demoland_data\"\n",
    "\n",
    "\n",
    "# regional level files: (require previous editing)\n",
    "oas_centroids_file = f\"{data_folder}/processed/OA_centroids_TyneWear.gpkg\" # used for population origin\n",
    "oas_file = f\"{data_folder}/processed/authorities/OA_TyneWear.gpkg\" # needed for visualisation purposes\n",
    "region_lads_file = f\"{data_folder}/processed/authorities/LADs_tynewear.shp\" # needed in order to filter greenspace data within the regional boundaries\n",
    "workingplacezones_centroids_file = f\"{data_folder}/processed/authorities/WPZ_centroids_tynewear.gpkg\" # needed for destinations centroids coordinates\n",
    "# greenspace_sites_file = f\"{data_folder}/processed/accessibility/greenspace-sites_tynewear.gpkg\" # needed for calcualting opportunities at greenspaces (area)\n",
    "# greenspace_entrances_file = f\"{data_folder}/processed/accessibility/accessTOgs_tynewear.gpkg\" # needed for destinations centroids coordinates\n",
    "greenspace_file = f\"{data_folder}/processed/accessibility/greenspace_tynewear_edited.gpkg\"\n",
    "jobs_file = f\"{data_folder}/processed/accessibility/wpz_tynewear_occupation_edited.csv\"\n",
    "\n",
    "# national level files\n",
    "# greenspace_file = f\"{data_folder}/raw/accessibility/OS Open Greenspace (GPKG) GB/data/opgrsp_gb.gpkg\"\n",
    "osm_data_file = f\"{data_folder}/raw/accessibility/tyne-and-wear-latest.osm.pbf\"\n",
    "gtfs_data_file = f\"{data_folder}/raw/accessibility/itm_north_east_gtfs.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# origins (IE output areas, OAs)\n",
    "oas_centroids = gpd.read_file(oas_centroids_file,\n",
    "                              layer=\"OA_centroids_TyneWear\")\n",
    "oas_centroids['id'] = oas_centroids['OA11CD'] # Origin dataset must contain an 'id' column for r5py\n",
    "oas_centroids.head()\n",
    "\n",
    "# destination data\n",
    "# green space sites' entrances\n",
    "gs_entrances = gpd.read_file(greenspace_file,\n",
    "                        layer = \"access_points\")\n",
    "\n",
    "gs_entrances.head() # Destination dataset already contains an 'id' column\n",
    "# WPZ centroids\n",
    "wpz_centroids = gpd.read_file(workingplacezones_centroids_file,\n",
    "                              layer = \"WPZ_centroids_tynewear\")\n",
    "wpz_centroids.head()\n",
    "wpz_centroids['id'] = wpz_centroids['wz11cd'] # Destination dataset must contain an 'id' column for r5py\n",
    "\n",
    "gs_sites = gpd.read_file(greenspace_file,\n",
    "                         layer = \"sites\")\n",
    "\n",
    "# network data\n",
    "# uploaded in the sequent operation\n",
    "\n",
    "# opportunities / land use data\n",
    "jobs_per_wpz_df = pd.read_csv(jobs_file) # working place zones, population (as a proxy for n of jobs)\n",
    "# note: opportunities column is called \"pop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_entrances.explore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRS conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the original files' crs to GWS84, which is compatible with GTFS and OSM data\n",
    "oas_centroids_wgs84 = oas_centroids.to_crs(\"epsg:4326\")\n",
    "gs_entrances = gs_entrances.to_crs(\"epsg:4326\")\n",
    "# gs_sites = gs_sites.to_crs(\"epsg:4326\") # let's leave the layer in epsg:27700, as we need the prj for calculating the areas\n",
    "wpz_centroids = wpz_centroids.to_crs(\"epsg:4326\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origins and destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oas_centroids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpz_centroids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_entrances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Â origins:\n",
    "#   OAs\n",
    "# destinations:\n",
    "#   gs: entrances + OAs centroids\n",
    "#   jobs: wpz centroids + OAs centroids\n",
    "# total destination: OAs centroids + wpz centroids + gs entrances\n",
    "\n",
    "origins = oas_centroids_wgs84\n",
    "\n",
    "# destinations common fields: 'id', 'geometry'\n",
    "# simply concatenate the dataframes...\n",
    "# need to keep the info on greenspace site's name to link with the entrances later on\n",
    "\n",
    "destinations = pd.concat([oas_centroids_wgs84[['id', 'geometry']],\n",
    "                          wpz_centroids[['id', 'geometry']],\n",
    "                          gs_entrances[['id', 'geometry', 'refToGreenspaceSite']]]\n",
    "                         ).reset_index(drop = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs: n of employees per WPZ\n",
    "# greenspace: area of site\n",
    "\n",
    "\n",
    "# add column with opportunity ... one for all?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Travel time matrix computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the transport network\n",
    "\n",
    "Compute the network starting from OSM and GTFS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in transport network\n",
    "transport_network = TransportNetwork(\n",
    "    osm_data_file,\n",
    "    [\n",
    "        gtfs_data_file\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an empty matrix that contains all origins and destinations to be used later on\n",
    "\n",
    "This table will be filled up once we calculate the ttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for testing purposes:\n",
    "k = 1000\n",
    "# selecting first n rows of dataframe for origins and destinations\n",
    "# origins = oas_centroids.loc[:k, :]\n",
    "# destinations = wpz_centroids.loc[:n, :]\n",
    "# selecting random rows, so to make sure we have both wpz AND gs_entrances in the selection of destinations\n",
    "origins = origins.sample(n=k)\n",
    "destinations = destinations.sample(n=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_id</th>\n",
       "      <th>to_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00041377</td>\n",
       "      <td>E33000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00041377</td>\n",
       "      <td>E33000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00041377</td>\n",
       "      <td>E33000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00041377</td>\n",
       "      <td>E33000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00041377</td>\n",
       "      <td>E33000174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     from_id      to_id\n",
       "0  E00041377  E33000251\n",
       "1  E00041377  E33000799\n",
       "2  E00041377  E33000257\n",
       "3  E00041377  E33000079\n",
       "4  E00041377  E33000174"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate dataframe with all from_id and all to_id pairs\n",
    "# (empty for now, to be filled up later on)\n",
    "prod = product(origins['id'].unique(),\n",
    "               destinations['id'].unique())\n",
    "empty_ttm = pd.DataFrame(prod)\n",
    "empty_ttm.columns = ['from_id', 'to_id']\n",
    "empty_ttm.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travel time matrix\n",
    "\n",
    "The following piece of code is split in 2:\n",
    "- first part is definition of variables that will be inputted as parameters in the ttm computation\n",
    "- second part is the loop to generate ttm for several transport modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables\n",
    "date_time = '2023,01,19,9,30' # CHOOSE BEST DATE/TIME\n",
    "# max_time = dt.timedelta(seconds=900) # SET TO 15 MIN\n",
    "walking_speed = 4.8\n",
    "cycling_speed = 16\n",
    "# dataframe to match legmode and transitmode objects (to be inputted in the ttm computer):\n",
    "modes_lut = pd.DataFrame([\n",
    "                          ['transit', TransitMode.TRANSIT, LegMode.WALK],\n",
    "                          ['car', '', LegMode.CAR],\n",
    "                          ['bicycle', '', LegMode.BICYCLE],\n",
    "                          ['walk','', LegMode.WALK],\n",
    "                         ],\n",
    "                         columns = ('Mode', 'Transit_mode', 'Leg_mode'))\n",
    "\n",
    "# function to generate custom list of transit+transport mode for the parameter transport_modes in TravelTimeMatrixComputer\n",
    "def list_making(s,z):\n",
    "    return [s] + [z]\n",
    "\n",
    "ttm_complete = empty_ttm\n",
    "\n",
    "# loop to compute a ttm for all the modes and generate one single ttm table in output\n",
    "for row in modes_lut.itertuples():\n",
    "    start_time = dt.datetime.now()\n",
    "    mode = row.Mode\n",
    "    transit_mode = row.Transit_mode\n",
    "    leg_mode = row.Leg_mode\n",
    "    transport_mode = list_making(transit_mode,leg_mode) # creating list of objects for transport_modes parameter\n",
    "\n",
    "    print('The current mode is:', mode, ', transit is:', transit_mode, ', transport var is:', transport_mode)\n",
    "    ttm_computer = TravelTimeMatrixComputer(\n",
    "        transport_network,\n",
    "        origins = origins,\n",
    "        destinations = destinations,\n",
    "        departure = dt.datetime.strptime(date_time, '%Y,%m,%d,%H,%M'),\n",
    "        # max_time = max_time,\n",
    "        speed_walking = walking_speed,\n",
    "        speed_cycling = cycling_speed,\n",
    "        transport_modes = transport_mode\n",
    "    )\n",
    "\n",
    "    ttm = ttm_computer.compute_travel_times()\n",
    "    ttm = ttm.rename(columns = {'travel_time':f'time_{mode}'}) # renaming 'travel_time' column (automatically generated) to 'time_{mode of transport}'\n",
    "    ttm.isna().sum() # checking for empty values, to see if the ttm actually calculated something\n",
    "    #  merging the empty table generated before (with all possible origins and destinations) with the ttm, per each mode adding a travel time column\n",
    "    ttm_complete = ttm_complete.merge(ttm,\n",
    "                    how ='outer',\n",
    "                    left_on = ['from_id','to_id'],\n",
    "                    right_on = ['from_id','to_id'])\n",
    "    \n",
    "    print('finished calculating ttm for mode', mode)\n",
    "    end_time = datetime.now()\n",
    "    print('Duration for', mode, ': {}'.format(end_time - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accessibility calculation\n",
    "\n",
    "Using [jamaps/tracc](https://github.com/jamaps/tracc) package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessibility to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm_jobs = ttm_complete.copy(deep=True) # saving a copy of the matrix (the following operations will add columns to it, but we want to keep the original one also)\n",
    "\n",
    "# generate tracc cost object\n",
    "ttm_jobs_tracc = tracc.costs(ttm_jobs)\n",
    "\n",
    "modes_list = ['transit',\n",
    "              'car',\n",
    "              'bicycle',\n",
    "              'walk']\n",
    "\n",
    "# empty dataframe to be filled up in the next for loop\n",
    "acc_pot_jobs = origins[['id']]\n",
    "\n",
    "for m in modes_list:\n",
    "    # generate variable names to be used in the tracc function below\n",
    "    cost_name = 'time_' + m\n",
    "    travel_costs_ids = [\"from_id\",\"to_id\"]\n",
    "    supplyID = \"wpz11cd\"\n",
    "    impedence_param = 15 # value for impedence function, to be changed as needed\n",
    "    impedence_param_string = str(impedence_param)\n",
    "    cost_output = 'cum_' + impedence_param_string + '_' + m\n",
    "    acc_column_name = 'pot_cum_acc_' + impedence_param_string + '_' + m\n",
    "    opportunity = \"pop\"\n",
    "# Computing impedance function based on a 15 minute travel time threshold.\n",
    "    ttm_jobs_tracc.impedence_calc(\n",
    "        cost_column = cost_name,\n",
    "        impedence_func = \"cumulative\",\n",
    "        impedence_func_params = impedence_param, # to calculate n of jobs in n min threshold\n",
    "        output_col_name = cost_output,\n",
    "        prune_output = False\n",
    "    )\n",
    "\n",
    "# Setting up the accessibility object. This includes joining the destination data to the travel time data\n",
    "    acc_jobs= tracc.accessibility(\n",
    "            travelcosts_df = ttm_jobs_tracc.data,\n",
    "            supply_df = jobs_per_wpz_df,\n",
    "            travelcosts_ids = travel_costs_ids,\n",
    "            supply_ids = supplyID\n",
    "        )\n",
    "    acc_jobs.data.head()\n",
    "\n",
    "# Measuring potential accessibility to jobs, using a 45 minute cumulative impedance function\n",
    "    # acc_pot_jobs = acc_jobs.potential(\n",
    "    #         opportunity = \"pop\",\n",
    "    #         impedence = cost_output,\n",
    "    #         output_col_name= \"pot_acc_\" + cost_output\n",
    "    #         )\n",
    "    # the above function generate overwrite the column at every loop\n",
    "    # so we reproduce the same function (from tracc documentation) per each mode:\n",
    "    acc_jobs.data[acc_column_name] = acc_jobs.data[opportunity] * acc_jobs.data[cost_output]\n",
    "    group_sum_bymode_acc = acc_jobs.data.groupby(acc_jobs.data[travel_costs_ids[0]])[[acc_column_name]].sum()\n",
    "    acc_pot_jobs = acc_pot_jobs.merge(group_sum_bymode_acc,\n",
    "                    how ='outer',\n",
    "                    left_on = 'id',\n",
    "                    right_on = 'from_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_jobs.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_pot_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving output to external file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessibility to greenspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit greenspace layers\n",
    "# change the 'id' column name, as it's the same in both layers and generates issues later on\n",
    "gs_entrances.columns # ['id', 'accessType', 'refToGreenspaceSite', 'geometry']\n",
    "gs_entrances.rename(columns={'id':'id_entrance'},\n",
    "                    inplace=True)\n",
    "gs_sites.columns # ['id', 'function', 'geometry']\n",
    "gs_sites.rename(columns={'id':'id_site'},\n",
    "                inplace=True)\n",
    "\n",
    "# calculates sites' area:\n",
    "gs_sites['area_m2'] = gs_sites['geometry'].area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_entrances.head()\n",
    "gs_sites.head()\n",
    "gs_sites.explore(column='area_m2',\n",
    "                       cmap=\"plasma\",\n",
    "                       scheme='NaturalBreaks',\n",
    "                       k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_entrances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate park area to entrances\n",
    "gs_entrances_with_parkarea = pd.merge(gs_entrances[['id_entrance','refToGreenspaceSite']],\n",
    "                                gs_sites[['id_site', 'function','area_m2']],\n",
    "                                left_on='refToGreenspaceSite',\n",
    "                                right_on='id_site',\n",
    "                                how='right'\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_entrances_with_parkarea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm_greenspace = ttm_complete.copy() # saving a copy of the matrix (the following operations will add columns to it, but we want to keep the original one also)\n",
    "\n",
    "\n",
    "ttm_gs_with_area =  pd.merge(ttm_greenspace,\n",
    "                            gs_entrances_with_parkarea[['id_entrance','refToGreenspaceSite', 'area_m2']],\n",
    "                            left_on='to_id',\n",
    "                            right_on='id_entrance',\n",
    "                            how='left'\n",
    "                            )\n",
    "# generate tracc cost object\n",
    "ttm_gs_tracc = tracc.costs(ttm_gs_with_area)\n",
    "\n",
    "modes_list = ['transit',\n",
    "              'car',\n",
    "              'bicycle',\n",
    "              'walk']\n",
    "\n",
    "# empty dataframes to be filled up in the next for loop\n",
    "acc_pot_gs = origins[['id']]\n",
    "gs_acc = []\n",
    "\n",
    "for m in modes_list:\n",
    "    # generate variable names to be used in the tracc function below\n",
    "    cost_name = 'time_' + m\n",
    "    travel_costs_ids = [\"from_id\",\"to_id\"]\n",
    "    impedence_param = 15 # value for impedence function, to be changed as needed\n",
    "    impedence_param_string = str(impedence_param)\n",
    "    # name of the column\n",
    "    cost_output = 'cum_' + impedence_param_string + '_' + m # naming depends on impedence function threshold\n",
    "    area_column_name = 'area_' + impedence_param_string + '_' + m\n",
    "    acc_column_name = 'pot_cum_acc_' + impedence_param_string + '_' + m # naming depends on impedence function threshold\n",
    "    opportunity = \"pop\"\n",
    "# Computing impedence function based on a 15 minute travel time threshold.\n",
    "    ttm_gs_tracc.impedence_calc(\n",
    "        cost_column = cost_name,\n",
    "        impedence_func = \"cumulative\",\n",
    "        impedence_func_params = impedence_param, # to calculate opportunities in X min threshold\n",
    "        output_col_name = cost_output,\n",
    "        prune_output = False\n",
    "    )\n",
    "    ttm_gs_df = ttm_gs_tracc.data\n",
    "    print(ttm_gs_df.columns)\n",
    "# Setting up the accessibility object. This includes joining the destination data to the travel time data\n",
    "# this needed to be done differently for greenspace, as opportunity is sites's area cumulative sum\n",
    "# A. Filtering only rows with time travel within the threshold\n",
    "    print(\"cost output is\", cost_output)\n",
    "    print('area column name is', area_column_name)\n",
    "    # tracc_15min = ttm_gs_tracc.data[ttm_gs_tracc.data.loc[:,cost_output]==1] # this doesn't work because of the different lenghts of the columns generated per mode\n",
    "    ttm_gs_tracc.data[area_column_name] =  ttm_gs_tracc.data['area_m2'] * ttm_gs_tracc.data[cost_output]\n",
    "    ttm_gs_df = ttm_gs_tracc.data\n",
    "\n",
    "# B. Filter entrances (only one per park)\n",
    "    oneaccess_perpark = ttm_gs_df.sort_values(cost_name).drop_duplicates([\"from_id\", \"refToGreenspaceSite\"])\n",
    "    oneaccess_perpark.head()\n",
    "# C. Assign metric as sum[parks' area]\n",
    "    # generate df with one row per OA centroid ('from_id') and sum of sites' areas - per each mode\n",
    "    gs_metric_per_mode = oneaccess_perpark.groupby(['from_id'])[area_column_name].sum() #.reset_index()\n",
    "    gs_acc.append(gs_metric_per_mode)\n",
    "gs_acc = pd.concat(gs_acc,\n",
    "                   axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oas_boundaries = gpd.read_file(oas_file,\n",
    "                               layer=\"OA_TyneWear\")\n",
    "oas_boundaries_wgs84 = oas_boundaries.to_crs(\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oas_boundaries_metric = oas_boundaries_wgs84.merge(gs_acc,\n",
    "                                                     left_on = 'geo_code',\n",
    "                                                     right_on = \"from_id\",\n",
    "                                                     how = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oas_boundaries_metric.explore(column='area_15_transit',\n",
    "                              cmap=\"plasma\",\n",
    "                              scheme='NaturalBreaks',\n",
    "                              k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oas_boundaries_metric.explore(column='area_15_car',\n",
    "                              cmap=\"plasma\",\n",
    "                              scheme='NaturalBreaks',\n",
    "                              k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demoland_r5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
